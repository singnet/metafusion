<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module multigen.pipelines.masked_stable_diffusion_xl_img2img</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong><a href="multigen.html"><font color="#ffffff">multigen</font></a>.<a href="multigen.pipelines.html"><font color="#ffffff">pipelines</font></a>.masked_stable_diffusion_xl_img2img</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:/home/imgen/projects/metafusion/multigen/pipelines/masked_stable_diffusion_xl_img2img.py">/home/imgen/projects/metafusion/multigen/pipelines/masked_stable_diffusion_xl_img2img.py</a></font></td></tr></table>
    <p></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="PIL.html">PIL</a><br>
<a href="inspect.html">inspect</a><br>
</td><td width="25%" valign=top><a href="diffusers.utils.logging.html">diffusers.utils.logging</a><br>
<a href="numpy.html">numpy</a><br>
</td><td width="25%" valign=top><a href="torch.html">torch</a><br>
</td><td width="25%" valign=top></td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.html#StableDiffusionXLImg2ImgPipeline">diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.StableDiffusionXLImg2ImgPipeline</a>(<a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a>, <a href="diffusers.pipelines.pipeline_utils.html#StableDiffusionMixin">diffusers.pipelines.pipeline_utils.StableDiffusionMixin</a>, <a href="diffusers.loaders.textual_inversion.html#TextualInversionLoaderMixin">diffusers.loaders.textual_inversion.TextualInversionLoaderMixin</a>, <a href="diffusers.loaders.single_file.html#FromSingleFileMixin">diffusers.loaders.single_file.FromSingleFileMixin</a>, <a href="diffusers.loaders.lora_pipeline.html#StableDiffusionXLLoraLoaderMixin">diffusers.loaders.lora_pipeline.StableDiffusionXLLoraLoaderMixin</a>, <a href="diffusers.loaders.ip_adapter.html#IPAdapterMixin">diffusers.loaders.ip_adapter.IPAdapterMixin</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="multigen.pipelines.masked_stable_diffusion_xl_img2img.html#MaskedStableDiffusionXLImg2ImgPipeline">MaskedStableDiffusionXLImg2ImgPipeline</a>
</font></dt></dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="MaskedStableDiffusionXLImg2ImgPipeline">class <strong>MaskedStableDiffusionXLImg2ImgPipeline</strong></a>(<a href="diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.html#StableDiffusionXLImg2ImgPipeline">diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.StableDiffusionXLImg2ImgPipeline</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt><a href="#MaskedStableDiffusionXLImg2ImgPipeline">MaskedStableDiffusionXLImg2ImgPipeline</a>(vae:&nbsp;diffusers.models.autoencoders.autoencoder_kl.AutoencoderKL,&nbsp;text_encoder:&nbsp;transformers.models.clip.modeling_clip.CLIPTextModel,&nbsp;text_encoder_2:&nbsp;transformers.models.clip.modeling_clip.CLIPTextModelWithProjection,&nbsp;tokenizer:&nbsp;transformers.models.clip.tokenization_clip.CLIPTokenizer,&nbsp;tokenizer_2:&nbsp;transformers.models.clip.tokenization_clip.CLIPTokenizer,&nbsp;unet:&nbsp;diffusers.models.unets.unet_2d_condition.UNet2DConditionModel,&nbsp;scheduler:&nbsp;diffusers.schedulers.scheduling_utils.KarrasDiffusionSchedulers,&nbsp;image_encoder:&nbsp;transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection&nbsp;=&nbsp;None,&nbsp;feature_extractor:&nbsp;transformers.models.clip.image_processing_clip.CLIPImageProcessor&nbsp;=&nbsp;None,&nbsp;requires_aesthetics_score:&nbsp;bool&nbsp;=&nbsp;False,&nbsp;force_zeros_for_empty_prompt:&nbsp;bool&nbsp;=&nbsp;True,&nbsp;add_watermarker:&nbsp;Optional[bool]&nbsp;=&nbsp;None)<br>
&nbsp;<br>
<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="multigen.pipelines.masked_stable_diffusion_xl_img2img.html#MaskedStableDiffusionXLImg2ImgPipeline">MaskedStableDiffusionXLImg2ImgPipeline</a></dd>
<dd><a href="diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.html#StableDiffusionXLImg2ImgPipeline">diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.StableDiffusionXLImg2ImgPipeline</a></dd>
<dd><a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a></dd>
<dd><a href="diffusers.configuration_utils.html#ConfigMixin">diffusers.configuration_utils.ConfigMixin</a></dd>
<dd><a href="diffusers.utils.hub_utils.html#PushToHubMixin">diffusers.utils.hub_utils.PushToHubMixin</a></dd>
<dd><a href="diffusers.pipelines.pipeline_utils.html#StableDiffusionMixin">diffusers.pipelines.pipeline_utils.StableDiffusionMixin</a></dd>
<dd><a href="diffusers.loaders.textual_inversion.html#TextualInversionLoaderMixin">diffusers.loaders.textual_inversion.TextualInversionLoaderMixin</a></dd>
<dd><a href="diffusers.loaders.single_file.html#FromSingleFileMixin">diffusers.loaders.single_file.FromSingleFileMixin</a></dd>
<dd><a href="diffusers.loaders.lora_pipeline.html#StableDiffusionXLLoraLoaderMixin">diffusers.loaders.lora_pipeline.StableDiffusionXLLoraLoaderMixin</a></dd>
<dd><a href="diffusers.loaders.lora_base.html#LoraBaseMixin">diffusers.loaders.lora_base.LoraBaseMixin</a></dd>
<dd><a href="diffusers.loaders.ip_adapter.html#IPAdapterMixin">diffusers.loaders.ip_adapter.IPAdapterMixin</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-__call__"><strong>__call__</strong></a>(self, prompt: Union[str, List[str]] = None, prompt_2: Union[str, List[str], NoneType] = None, image: Union[PIL.Image.Image, numpy.ndarray, torch.Tensor, List[PIL.Image.Image], List[numpy.ndarray], List[torch.Tensor]] = None, original_image: Union[PIL.Image.Image, numpy.ndarray, torch.Tensor, List[PIL.Image.Image], List[numpy.ndarray], List[torch.Tensor]] = None, strength: float = 0.3, num_inference_steps: Optional[int] = 50, timesteps: List[int] = None, denoising_start: Optional[float] = None, denoising_end: Optional[float] = None, guidance_scale: Optional[float] = 5.0, negative_prompt: Union[str, List[str], NoneType] = None, negative_prompt_2: Union[str, List[str], NoneType] = None, num_images_per_prompt: Optional[int] = 1, eta: Optional[float] = 0.0, generator: Union[torch._C.Generator, List[torch._C.Generator], NoneType] = None, latents: Optional[torch.FloatTensor] = None, prompt_embeds: Optional[torch.FloatTensor] = None, negative_prompt_embeds: Optional[torch.FloatTensor] = None, pooled_prompt_embeds: Optional[torch.FloatTensor] = None, negative_pooled_prompt_embeds: Optional[torch.FloatTensor] = None, ip_adapter_image: Union[PIL.Image.Image, numpy.ndarray, torch.Tensor, List[PIL.Image.Image], List[numpy.ndarray], List[torch.Tensor], NoneType] = None, ip_adapter_image_embeds: Optional[List[torch.FloatTensor]] = None, output_type: Optional[str] = 'pil', return_dict: bool = True, cross_attention_kwargs: Optional[Dict[str, Any]] = None, guidance_rescale: float = 0.0, original_size: Tuple[int, int] = None, crops_coords_top_left: Tuple[int, int] = (0, 0), target_size: Tuple[int, int] = None, negative_original_size: Optional[Tuple[int, int]] = None, negative_crops_coords_top_left: Tuple[int, int] = (0, 0), negative_target_size: Optional[Tuple[int, int]] = None, aesthetic_score: float = 6.0, negative_aesthetic_score: float = 2.5, clip_skip: Optional[int] = None, callback_on_step_end: Optional[Callable[[int, int, Dict], NoneType]] = None, callback_on_step_end_tensor_inputs: List[str] = ['latents'], mask: Union[torch.FloatTensor, PIL.Image.Image, numpy.ndarray, List[torch.FloatTensor], List[PIL.Image.Image], List[numpy.ndarray]] = None, sample_mode='sample', **kwargs)</dt><dd><tt>The&nbsp;call&nbsp;function&nbsp;to&nbsp;the&nbsp;pipeline&nbsp;for&nbsp;generation.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;prompt&nbsp;or&nbsp;prompts&nbsp;to&nbsp;guide&nbsp;image&nbsp;generation.&nbsp;If&nbsp;not&nbsp;defined,&nbsp;you&nbsp;need&nbsp;to&nbsp;pass&nbsp;`prompt_embeds`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;(`torch.FloatTensor`,&nbsp;`PIL.Image.Image`,&nbsp;`np.ndarray`,&nbsp;`List[torch.FloatTensor]`,&nbsp;`List[PIL.Image.Image]`,&nbsp;or&nbsp;`List[np.ndarray]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`Image`&nbsp;or&nbsp;tensor&nbsp;representing&nbsp;an&nbsp;image&nbsp;batch&nbsp;to&nbsp;be&nbsp;used&nbsp;as&nbsp;the&nbsp;starting&nbsp;point.&nbsp;Can&nbsp;also&nbsp;accept&nbsp;image<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;latents&nbsp;as&nbsp;`image`,&nbsp;but&nbsp;if&nbsp;passing&nbsp;latents&nbsp;directly&nbsp;it&nbsp;is&nbsp;not&nbsp;encoded&nbsp;again.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strength&nbsp;(`float`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;0.8):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Indicates&nbsp;extent&nbsp;to&nbsp;transform&nbsp;the&nbsp;reference&nbsp;`image`.&nbsp;Must&nbsp;be&nbsp;between&nbsp;0&nbsp;and&nbsp;1.&nbsp;`image`&nbsp;is&nbsp;used&nbsp;as&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;starting&nbsp;point&nbsp;and&nbsp;more&nbsp;noise&nbsp;is&nbsp;added&nbsp;the&nbsp;higher&nbsp;the&nbsp;`strength`.&nbsp;The&nbsp;number&nbsp;of&nbsp;denoising&nbsp;steps&nbsp;depends<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on&nbsp;the&nbsp;amount&nbsp;of&nbsp;noise&nbsp;initially&nbsp;added.&nbsp;When&nbsp;`strength`&nbsp;is&nbsp;1,&nbsp;added&nbsp;noise&nbsp;is&nbsp;maximum&nbsp;and&nbsp;the&nbsp;denoising<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;process&nbsp;runs&nbsp;for&nbsp;the&nbsp;full&nbsp;number&nbsp;of&nbsp;iterations&nbsp;specified&nbsp;in&nbsp;`num_inference_steps`.&nbsp;A&nbsp;value&nbsp;of&nbsp;1<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;essentially&nbsp;ignores&nbsp;`image`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_inference_steps&nbsp;(`int`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;50):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;denoising&nbsp;steps.&nbsp;More&nbsp;denoising&nbsp;steps&nbsp;usually&nbsp;lead&nbsp;to&nbsp;a&nbsp;higher&nbsp;quality&nbsp;image&nbsp;at&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expense&nbsp;of&nbsp;slower&nbsp;inference.&nbsp;This&nbsp;parameter&nbsp;is&nbsp;modulated&nbsp;by&nbsp;`strength`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;guidance_scale&nbsp;(`float`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;7.5):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;higher&nbsp;guidance&nbsp;scale&nbsp;value&nbsp;encourages&nbsp;the&nbsp;model&nbsp;to&nbsp;generate&nbsp;images&nbsp;closely&nbsp;linked&nbsp;to&nbsp;the&nbsp;text<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,`prompt`&nbsp;at&nbsp;the&nbsp;expense&nbsp;of&nbsp;lower&nbsp;image&nbsp;quality.&nbsp;Guidance&nbsp;scale&nbsp;is&nbsp;enabled&nbsp;when&nbsp;`guidance_scale&nbsp;&gt;&nbsp;1`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative_prompt&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;prompt&nbsp;or&nbsp;prompts&nbsp;to&nbsp;guide&nbsp;what&nbsp;to&nbsp;not&nbsp;include&nbsp;in&nbsp;image&nbsp;generation.&nbsp;If&nbsp;not&nbsp;defined,&nbsp;you&nbsp;need&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pass&nbsp;`negative_prompt_embeds`&nbsp;instead.&nbsp;Ignored&nbsp;when&nbsp;not&nbsp;using&nbsp;guidance&nbsp;(`guidance_scale&nbsp;&lt;&nbsp;1`).<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_images_per_prompt&nbsp;(`int`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;1):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;images&nbsp;to&nbsp;generate&nbsp;per&nbsp;prompt.<br>
&nbsp;&nbsp;&nbsp;&nbsp;eta&nbsp;(`float`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;0.0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Corresponds&nbsp;to&nbsp;parameter&nbsp;eta&nbsp;(Œ∑)&nbsp;from&nbsp;the&nbsp;[DDIM](<a href="https://arxiv.org/abs/2010.02502">https://arxiv.org/abs/2010.02502</a>)&nbsp;paper.&nbsp;Only&nbsp;applies<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;[`~schedulers.DDIMScheduler`],&nbsp;and&nbsp;is&nbsp;ignored&nbsp;in&nbsp;other&nbsp;schedulers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;generator&nbsp;(`torch.Generator`&nbsp;or&nbsp;`List[torch.Generator]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;[`torch.Generator`](<a href="https://pytorch.org/docs/stable/generated/torch.Generator.html">https://pytorch.org/docs/stable/generated/torch.Generator.html</a>)&nbsp;to&nbsp;make<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;generation&nbsp;deterministic.<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt_embeds&nbsp;(`torch.FloatTensor`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pre-generated&nbsp;text&nbsp;embeddings.&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;easily&nbsp;tweak&nbsp;text&nbsp;inputs&nbsp;(prompt&nbsp;weighting).&nbsp;If&nbsp;not<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;provided,&nbsp;text&nbsp;embeddings&nbsp;are&nbsp;generated&nbsp;from&nbsp;the&nbsp;`prompt`&nbsp;input&nbsp;argument.<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative_prompt_embeds&nbsp;(`torch.FloatTensor`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pre-generated&nbsp;negative&nbsp;text&nbsp;embeddings.&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;easily&nbsp;tweak&nbsp;text&nbsp;inputs&nbsp;(prompt&nbsp;weighting).&nbsp;If<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;not&nbsp;provided,&nbsp;`negative_prompt_embeds`&nbsp;are&nbsp;generated&nbsp;from&nbsp;the&nbsp;`negative_prompt`&nbsp;input&nbsp;argument.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_type&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"pil"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;output&nbsp;format&nbsp;of&nbsp;the&nbsp;generated&nbsp;image.&nbsp;Choose&nbsp;between&nbsp;`PIL.Image`&nbsp;or&nbsp;`np.array`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_dict&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;return&nbsp;a&nbsp;[`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`]&nbsp;instead&nbsp;of&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plain&nbsp;tuple.<br>
&nbsp;&nbsp;&nbsp;&nbsp;callback&nbsp;(`Callable`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;function&nbsp;that&nbsp;calls&nbsp;every&nbsp;`callback_steps`&nbsp;steps&nbsp;during&nbsp;inference.&nbsp;The&nbsp;function&nbsp;is&nbsp;called&nbsp;with&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;following&nbsp;arguments:&nbsp;`callback(step:&nbsp;int,&nbsp;timestep:&nbsp;int,&nbsp;latents:&nbsp;torch.FloatTensor)`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;callback_steps&nbsp;(`int`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;1):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;frequency&nbsp;at&nbsp;which&nbsp;the&nbsp;`callback`&nbsp;function&nbsp;is&nbsp;called.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;the&nbsp;callback&nbsp;is&nbsp;called&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;every&nbsp;step.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cross_attention_kwargs&nbsp;(`dict`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;kwargs&nbsp;dictionary&nbsp;that&nbsp;if&nbsp;specified&nbsp;is&nbsp;passed&nbsp;along&nbsp;to&nbsp;the&nbsp;[`AttentionProcessor`]&nbsp;as&nbsp;defined&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[`self.<strong>processor</strong>`](<a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py">https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py</a>).<br>
&nbsp;&nbsp;&nbsp;&nbsp;mask&nbsp;(`torch.FloatTensor`,&nbsp;`PIL.Image.Image`,&nbsp;`np.ndarray`,&nbsp;`List[torch.FloatTensor]`,&nbsp;`List[PIL.Image.Image]`,&nbsp;or&nbsp;`List[np.ndarray]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;mask&nbsp;with&nbsp;non-zero&nbsp;elements&nbsp;for&nbsp;the&nbsp;area&nbsp;to&nbsp;be&nbsp;inpainted.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;no&nbsp;mask&nbsp;is&nbsp;applied.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_mode&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;control&nbsp;latents&nbsp;initialisation&nbsp;for&nbsp;the&nbsp;inpaint&nbsp;area,&nbsp;can&nbsp;be&nbsp;one&nbsp;of&nbsp;sample,&nbsp;argmax,&nbsp;random<br>
Examples:<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;[`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`]&nbsp;or&nbsp;`tuple`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;`return_dict`&nbsp;is&nbsp;`True`,&nbsp;[`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`]&nbsp;is&nbsp;returned,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;otherwise&nbsp;a&nbsp;`tuple`&nbsp;is&nbsp;returned&nbsp;where&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;a&nbsp;list&nbsp;with&nbsp;the&nbsp;generated&nbsp;images&nbsp;and&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;second&nbsp;element&nbsp;is&nbsp;a&nbsp;list&nbsp;of&nbsp;`bool`s&nbsp;indicating&nbsp;whether&nbsp;the&nbsp;corresponding&nbsp;generated&nbsp;image&nbsp;contains<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"not-safe-for-work"&nbsp;(nsfw)&nbsp;content.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-denormalize"><strong>denormalize</strong></a>(self, latents)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-latents_to_img"><strong>latents_to_img</strong></a>(self, latents)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-prepare_latents"><strong>prepare_latents</strong></a>(self, image, timestep, batch_size, num_images_per_prompt, dtype, device, generator=None, add_noise=True, sample_mode: str = 'sample')</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-random_latents"><strong>random_latents</strong></a>(self, batch_size, num_channels_latents, height, width, dtype, device, generator, latents=None)</dt><dd><tt>#&nbsp;Copied&nbsp;from&nbsp;diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.prepare_latents</tt></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>debug_save</strong> = 0</dl>

<hr>
Methods inherited from <a href="diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.html#StableDiffusionXLImg2ImgPipeline">diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.StableDiffusionXLImg2ImgPipeline</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-__init__"><strong>__init__</strong></a>(self, vae: diffusers.models.autoencoders.autoencoder_kl.AutoencoderKL, text_encoder: transformers.models.clip.modeling_clip.CLIPTextModel, text_encoder_2: transformers.models.clip.modeling_clip.CLIPTextModelWithProjection, tokenizer: transformers.models.clip.tokenization_clip.CLIPTokenizer, tokenizer_2: transformers.models.clip.tokenization_clip.CLIPTokenizer, unet: diffusers.models.unets.unet_2d_condition.UNet2DConditionModel, scheduler: diffusers.schedulers.scheduling_utils.KarrasDiffusionSchedulers, image_encoder: transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection = None, feature_extractor: transformers.models.clip.image_processing_clip.CLIPImageProcessor = None, requires_aesthetics_score: bool = False, force_zeros_for_empty_prompt: bool = True, add_watermarker: Optional[bool] = None)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-check_inputs"><strong>check_inputs</strong></a>(self, prompt, prompt_2, strength, num_inference_steps, callback_steps, negative_prompt=None, negative_prompt_2=None, prompt_embeds=None, negative_prompt_embeds=None, ip_adapter_image=None, ip_adapter_image_embeds=None, callback_on_step_end_tensor_inputs=None)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-encode_image"><strong>encode_image</strong></a>(self, image, device, num_images_per_prompt, output_hidden_states=None)</dt><dd><tt>#&nbsp;Copied&nbsp;from&nbsp;diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.encode_image</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-encode_prompt"><strong>encode_prompt</strong></a>(self, prompt: str, prompt_2: Optional[str] = None, device: Optional[torch.device] = None, num_images_per_prompt: int = 1, do_classifier_free_guidance: bool = True, negative_prompt: Optional[str] = None, negative_prompt_2: Optional[str] = None, prompt_embeds: Optional[torch.Tensor] = None, negative_prompt_embeds: Optional[torch.Tensor] = None, pooled_prompt_embeds: Optional[torch.Tensor] = None, negative_pooled_prompt_embeds: Optional[torch.Tensor] = None, lora_scale: Optional[float] = None, clip_skip: Optional[int] = None)</dt><dd><tt>Encodes&nbsp;the&nbsp;prompt&nbsp;into&nbsp;text&nbsp;encoder&nbsp;hidden&nbsp;states.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;to&nbsp;be&nbsp;encoded<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt_2&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;prompt&nbsp;or&nbsp;prompts&nbsp;to&nbsp;be&nbsp;sent&nbsp;to&nbsp;the&nbsp;`tokenizer_2`&nbsp;and&nbsp;`text_encoder_2`.&nbsp;If&nbsp;not&nbsp;defined,&nbsp;`prompt`&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;used&nbsp;in&nbsp;both&nbsp;text-encoders<br>
&nbsp;&nbsp;&nbsp;&nbsp;device:&nbsp;(`torch.device`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;torch&nbsp;device<br>
&nbsp;&nbsp;&nbsp;&nbsp;num_images_per_prompt&nbsp;(`int`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number&nbsp;of&nbsp;images&nbsp;that&nbsp;should&nbsp;be&nbsp;generated&nbsp;per&nbsp;prompt<br>
&nbsp;&nbsp;&nbsp;&nbsp;do_classifier_free_guidance&nbsp;(`bool`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;whether&nbsp;to&nbsp;use&nbsp;classifier&nbsp;free&nbsp;guidance&nbsp;or&nbsp;not<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative_prompt&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;prompt&nbsp;or&nbsp;prompts&nbsp;not&nbsp;to&nbsp;guide&nbsp;the&nbsp;image&nbsp;generation.&nbsp;If&nbsp;not&nbsp;defined,&nbsp;one&nbsp;has&nbsp;to&nbsp;pass<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`negative_prompt_embeds`&nbsp;instead.&nbsp;Ignored&nbsp;when&nbsp;not&nbsp;using&nbsp;guidance&nbsp;(i.e.,&nbsp;ignored&nbsp;if&nbsp;`guidance_scale`&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;less&nbsp;than&nbsp;`1`).<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative_prompt_2&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;prompt&nbsp;or&nbsp;prompts&nbsp;not&nbsp;to&nbsp;guide&nbsp;the&nbsp;image&nbsp;generation&nbsp;to&nbsp;be&nbsp;sent&nbsp;to&nbsp;`tokenizer_2`&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`text_encoder_2`.&nbsp;If&nbsp;not&nbsp;defined,&nbsp;`negative_prompt`&nbsp;is&nbsp;used&nbsp;in&nbsp;both&nbsp;text-encoders<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt_embeds&nbsp;(`torch.Tensor`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pre-generated&nbsp;text&nbsp;embeddings.&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;easily&nbsp;tweak&nbsp;text&nbsp;inputs,&nbsp;*e.g.*&nbsp;prompt&nbsp;weighting.&nbsp;If&nbsp;not<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;provided,&nbsp;text&nbsp;embeddings&nbsp;will&nbsp;be&nbsp;generated&nbsp;from&nbsp;`prompt`&nbsp;input&nbsp;argument.<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative_prompt_embeds&nbsp;(`torch.Tensor`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pre-generated&nbsp;negative&nbsp;text&nbsp;embeddings.&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;easily&nbsp;tweak&nbsp;text&nbsp;inputs,&nbsp;*e.g.*&nbsp;prompt<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weighting.&nbsp;If&nbsp;not&nbsp;provided,&nbsp;negative_prompt_embeds&nbsp;will&nbsp;be&nbsp;generated&nbsp;from&nbsp;`negative_prompt`&nbsp;input<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;argument.<br>
&nbsp;&nbsp;&nbsp;&nbsp;pooled_prompt_embeds&nbsp;(`torch.Tensor`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pre-generated&nbsp;pooled&nbsp;text&nbsp;embeddings.&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;easily&nbsp;tweak&nbsp;text&nbsp;inputs,&nbsp;*e.g.*&nbsp;prompt&nbsp;weighting.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;not&nbsp;provided,&nbsp;pooled&nbsp;text&nbsp;embeddings&nbsp;will&nbsp;be&nbsp;generated&nbsp;from&nbsp;`prompt`&nbsp;input&nbsp;argument.<br>
&nbsp;&nbsp;&nbsp;&nbsp;negative_pooled_prompt_embeds&nbsp;(`torch.Tensor`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pre-generated&nbsp;negative&nbsp;pooled&nbsp;text&nbsp;embeddings.&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;easily&nbsp;tweak&nbsp;text&nbsp;inputs,&nbsp;*e.g.*&nbsp;prompt<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weighting.&nbsp;If&nbsp;not&nbsp;provided,&nbsp;pooled&nbsp;negative_prompt_embeds&nbsp;will&nbsp;be&nbsp;generated&nbsp;from&nbsp;`negative_prompt`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input&nbsp;argument.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lora_scale&nbsp;(`float`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;lora&nbsp;scale&nbsp;that&nbsp;will&nbsp;be&nbsp;applied&nbsp;to&nbsp;all&nbsp;LoRA&nbsp;layers&nbsp;of&nbsp;the&nbsp;text&nbsp;encoder&nbsp;if&nbsp;LoRA&nbsp;layers&nbsp;are&nbsp;loaded.<br>
&nbsp;&nbsp;&nbsp;&nbsp;clip_skip&nbsp;(`int`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;of&nbsp;layers&nbsp;to&nbsp;be&nbsp;skipped&nbsp;from&nbsp;CLIP&nbsp;while&nbsp;computing&nbsp;the&nbsp;prompt&nbsp;embeddings.&nbsp;A&nbsp;value&nbsp;of&nbsp;1&nbsp;means&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;pre-final&nbsp;layer&nbsp;will&nbsp;be&nbsp;used&nbsp;for&nbsp;computing&nbsp;the&nbsp;prompt&nbsp;embeddings.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-get_guidance_scale_embedding"><strong>get_guidance_scale_embedding</strong></a>(self, w: torch.Tensor, embedding_dim: int = 512, dtype: torch.dtype = torch.float32) -&gt; torch.Tensor</dt><dd><tt>See&nbsp;<a href="https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298">https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</a><br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;(`torch.Tensor`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate&nbsp;embedding&nbsp;vectors&nbsp;with&nbsp;a&nbsp;specified&nbsp;guidance&nbsp;scale&nbsp;to&nbsp;subsequently&nbsp;enrich&nbsp;timestep&nbsp;embeddings.<br>
&nbsp;&nbsp;&nbsp;&nbsp;embedding_dim&nbsp;(`int`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;512):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dimension&nbsp;of&nbsp;the&nbsp;embeddings&nbsp;to&nbsp;generate.<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(`torch.dtype`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`torch.float32`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data&nbsp;type&nbsp;of&nbsp;the&nbsp;generated&nbsp;embeddings.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`torch.Tensor`:&nbsp;Embedding&nbsp;vectors&nbsp;with&nbsp;shape&nbsp;`(len(w),&nbsp;embedding_dim)`.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-get_timesteps"><strong>get_timesteps</strong></a>(self, num_inference_steps, strength, device, denoising_start=None)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-prepare_extra_step_kwargs"><strong>prepare_extra_step_kwargs</strong></a>(self, generator, eta)</dt><dd><tt>#&nbsp;Copied&nbsp;from&nbsp;diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.prepare_extra_step_kwargs</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-prepare_ip_adapter_image_embeds"><strong>prepare_ip_adapter_image_embeds</strong></a>(self, ip_adapter_image, ip_adapter_image_embeds, device, num_images_per_prompt, do_classifier_free_guidance)</dt><dd><tt>#&nbsp;Copied&nbsp;from&nbsp;diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.prepare_ip_adapter_image_embeds</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-upcast_vae"><strong>upcast_vae</strong></a>(self)</dt><dd><tt>#&nbsp;Copied&nbsp;from&nbsp;diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_upscale.StableDiffusionUpscalePipeline.upcast_vae</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.html#StableDiffusionXLImg2ImgPipeline">diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.StableDiffusionXLImg2ImgPipeline</a>:<br>
<dl><dt><strong>clip_skip</strong></dt>
</dl>
<dl><dt><strong>cross_attention_kwargs</strong></dt>
</dl>
<dl><dt><strong>denoising_end</strong></dt>
</dl>
<dl><dt><strong>denoising_start</strong></dt>
</dl>
<dl><dt><strong>do_classifier_free_guidance</strong></dt>
</dl>
<dl><dt><strong>guidance_rescale</strong></dt>
</dl>
<dl><dt><strong>guidance_scale</strong></dt>
</dl>
<dl><dt><strong>interrupt</strong></dt>
</dl>
<dl><dt><strong>num_timesteps</strong></dt>
</dl>
<hr>
Data and other attributes inherited from <a href="diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.html#StableDiffusionXLImg2ImgPipeline">diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl_img2img.StableDiffusionXLImg2ImgPipeline</a>:<br>
<dl><dt><strong>model_cpu_offload_seq</strong> = 'text_encoder-&gt;text_encoder_2-&gt;image_encoder-&gt;unet-&gt;vae'</dl>

<hr>
Methods inherited from <a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-__setattr__"><strong>__setattr__</strong></a>(self, name: str, value: Any)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-disable_attention_slicing"><strong>disable_attention_slicing</strong></a>(self)</dt><dd><tt>Disable&nbsp;sliced&nbsp;attention&nbsp;computation.&nbsp;If&nbsp;`enable_attention_slicing`&nbsp;was&nbsp;previously&nbsp;called,&nbsp;attention&nbsp;is<br>
computed&nbsp;in&nbsp;one&nbsp;step.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-disable_xformers_memory_efficient_attention"><strong>disable_xformers_memory_efficient_attention</strong></a>(self)</dt><dd><tt>Disable&nbsp;memory&nbsp;efficient&nbsp;attention&nbsp;from&nbsp;[xFormers](<a href="https://facebookresearch.github.io/xformers/">https://facebookresearch.github.io/xformers/</a>).</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_attention_slicing"><strong>enable_attention_slicing</strong></a>(self, slice_size: Union[str, int, NoneType] = 'auto')</dt><dd><tt>Enable&nbsp;sliced&nbsp;attention&nbsp;computation.&nbsp;When&nbsp;this&nbsp;option&nbsp;is&nbsp;enabled,&nbsp;the&nbsp;attention&nbsp;module&nbsp;splits&nbsp;the&nbsp;input&nbsp;tensor<br>
in&nbsp;slices&nbsp;to&nbsp;compute&nbsp;attention&nbsp;in&nbsp;several&nbsp;steps.&nbsp;For&nbsp;more&nbsp;than&nbsp;one&nbsp;attention&nbsp;head,&nbsp;the&nbsp;computation&nbsp;is&nbsp;performed<br>
sequentially&nbsp;over&nbsp;each&nbsp;head.&nbsp;This&nbsp;is&nbsp;useful&nbsp;to&nbsp;save&nbsp;some&nbsp;memory&nbsp;in&nbsp;exchange&nbsp;for&nbsp;a&nbsp;small&nbsp;speed&nbsp;decrease.<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
‚ö†Ô∏è&nbsp;Don't&nbsp;enable&nbsp;attention&nbsp;slicing&nbsp;if&nbsp;you're&nbsp;already&nbsp;using&nbsp;`scaled_dot_product_attention`&nbsp;(SDPA)&nbsp;from&nbsp;PyTorch<br>
2.0&nbsp;or&nbsp;xFormers.&nbsp;These&nbsp;attention&nbsp;computations&nbsp;are&nbsp;already&nbsp;very&nbsp;memory&nbsp;efficient&nbsp;so&nbsp;you&nbsp;won't&nbsp;need&nbsp;to&nbsp;enable<br>
this&nbsp;function.&nbsp;If&nbsp;you&nbsp;enable&nbsp;attention&nbsp;slicing&nbsp;with&nbsp;SDPA&nbsp;or&nbsp;xFormers,&nbsp;it&nbsp;can&nbsp;lead&nbsp;to&nbsp;serious&nbsp;slow&nbsp;downs!<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;slice_size&nbsp;(`str`&nbsp;or&nbsp;`int`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"auto"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;When&nbsp;`"auto"`,&nbsp;halves&nbsp;the&nbsp;input&nbsp;to&nbsp;the&nbsp;attention&nbsp;heads,&nbsp;so&nbsp;attention&nbsp;will&nbsp;be&nbsp;computed&nbsp;in&nbsp;two&nbsp;steps.&nbsp;If<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`"max"`,&nbsp;maximum&nbsp;amount&nbsp;of&nbsp;memory&nbsp;will&nbsp;be&nbsp;saved&nbsp;by&nbsp;running&nbsp;only&nbsp;one&nbsp;slice&nbsp;at&nbsp;a&nbsp;time.&nbsp;If&nbsp;a&nbsp;number&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;provided,&nbsp;uses&nbsp;as&nbsp;many&nbsp;slices&nbsp;as&nbsp;`attention_head_dim&nbsp;//&nbsp;slice_size`.&nbsp;In&nbsp;this&nbsp;case,&nbsp;`attention_head_dim`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;must&nbsp;be&nbsp;a&nbsp;multiple&nbsp;of&nbsp;`slice_size`.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```py<br>
&gt;&gt;&gt;&nbsp;import&nbsp;torch<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;StableDiffusionPipeline<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;pipe&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>(<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"runwayml/stable-diffusion-v1-5",<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;torch_dtype=torch.float16,<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;use_safetensors=True,<br>
...&nbsp;)<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;prompt&nbsp;=&nbsp;"a&nbsp;photo&nbsp;of&nbsp;an&nbsp;astronaut&nbsp;riding&nbsp;a&nbsp;horse&nbsp;on&nbsp;mars"<br>
&gt;&gt;&gt;&nbsp;pipe.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-enable_attention_slicing">enable_attention_slicing</a>()<br>
&gt;&gt;&gt;&nbsp;image&nbsp;=&nbsp;pipe(prompt).images[0]<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_model_cpu_offload"><strong>enable_model_cpu_offload</strong></a>(self, gpu_id: Optional[int] = None, device: Union[torch.device, str] = 'cuda')</dt><dd><tt>Offloads&nbsp;all&nbsp;models&nbsp;to&nbsp;CPU&nbsp;using&nbsp;accelerate,&nbsp;reducing&nbsp;memory&nbsp;usage&nbsp;with&nbsp;a&nbsp;low&nbsp;impact&nbsp;on&nbsp;performance.&nbsp;Compared<br>
to&nbsp;`enable_sequential_cpu_offload`,&nbsp;this&nbsp;method&nbsp;moves&nbsp;one&nbsp;whole&nbsp;model&nbsp;at&nbsp;a&nbsp;time&nbsp;to&nbsp;the&nbsp;GPU&nbsp;when&nbsp;its&nbsp;`forward`<br>
method&nbsp;is&nbsp;called,&nbsp;and&nbsp;the&nbsp;model&nbsp;remains&nbsp;in&nbsp;GPU&nbsp;until&nbsp;the&nbsp;next&nbsp;model&nbsp;runs.&nbsp;Memory&nbsp;savings&nbsp;are&nbsp;lower&nbsp;than&nbsp;with<br>
`enable_sequential_cpu_offload`,&nbsp;but&nbsp;performance&nbsp;is&nbsp;much&nbsp;better&nbsp;due&nbsp;to&nbsp;the&nbsp;iterative&nbsp;execution&nbsp;of&nbsp;the&nbsp;`unet`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;gpu_id&nbsp;(`int`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;ID&nbsp;of&nbsp;the&nbsp;accelerator&nbsp;that&nbsp;shall&nbsp;be&nbsp;used&nbsp;in&nbsp;inference.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will&nbsp;default&nbsp;to&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(`torch.Device`&nbsp;or&nbsp;`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;"cuda"):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;PyTorch&nbsp;device&nbsp;type&nbsp;of&nbsp;the&nbsp;accelerator&nbsp;that&nbsp;shall&nbsp;be&nbsp;used&nbsp;in&nbsp;inference.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;default&nbsp;to&nbsp;"cuda".</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_sequential_cpu_offload"><strong>enable_sequential_cpu_offload</strong></a>(self, gpu_id: Optional[int] = None, device: Union[torch.device, str] = 'cuda')</dt><dd><tt>Offloads&nbsp;all&nbsp;models&nbsp;to&nbsp;CPU&nbsp;using&nbsp;ü§ó&nbsp;Accelerate,&nbsp;significantly&nbsp;reducing&nbsp;memory&nbsp;usage.&nbsp;When&nbsp;called,&nbsp;the&nbsp;state<br>
dicts&nbsp;of&nbsp;all&nbsp;`torch.nn.Module`&nbsp;components&nbsp;(except&nbsp;those&nbsp;in&nbsp;`self.<strong>_exclude_from_cpu_offload</strong>`)&nbsp;are&nbsp;saved&nbsp;to&nbsp;CPU<br>
and&nbsp;then&nbsp;moved&nbsp;to&nbsp;`torch.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-device">device</a>('meta')`&nbsp;and&nbsp;loaded&nbsp;to&nbsp;GPU&nbsp;only&nbsp;when&nbsp;their&nbsp;specific&nbsp;submodule&nbsp;has&nbsp;its&nbsp;`forward`<br>
method&nbsp;called.&nbsp;Offloading&nbsp;happens&nbsp;on&nbsp;a&nbsp;submodule&nbsp;basis.&nbsp;Memory&nbsp;savings&nbsp;are&nbsp;higher&nbsp;than&nbsp;with<br>
`enable_model_cpu_offload`,&nbsp;but&nbsp;performance&nbsp;is&nbsp;lower.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;gpu_id&nbsp;(`int`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;ID&nbsp;of&nbsp;the&nbsp;accelerator&nbsp;that&nbsp;shall&nbsp;be&nbsp;used&nbsp;in&nbsp;inference.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will&nbsp;default&nbsp;to&nbsp;0.<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(`torch.Device`&nbsp;or&nbsp;`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;"cuda"):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;PyTorch&nbsp;device&nbsp;type&nbsp;of&nbsp;the&nbsp;accelerator&nbsp;that&nbsp;shall&nbsp;be&nbsp;used&nbsp;in&nbsp;inference.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;default&nbsp;to&nbsp;"cuda".</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_xformers_memory_efficient_attention"><strong>enable_xformers_memory_efficient_attention</strong></a>(self, attention_op: Optional[Callable] = None)</dt><dd><tt>Enable&nbsp;memory&nbsp;efficient&nbsp;attention&nbsp;from&nbsp;[xFormers](<a href="https://facebookresearch.github.io/xformers/">https://facebookresearch.github.io/xformers/</a>).&nbsp;When&nbsp;this<br>
option&nbsp;is&nbsp;enabled,&nbsp;you&nbsp;should&nbsp;observe&nbsp;lower&nbsp;GPU&nbsp;memory&nbsp;usage&nbsp;and&nbsp;a&nbsp;potential&nbsp;speed&nbsp;up&nbsp;during&nbsp;inference.&nbsp;Speed<br>
up&nbsp;during&nbsp;training&nbsp;is&nbsp;not&nbsp;guaranteed.<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
‚ö†Ô∏è&nbsp;When&nbsp;memory&nbsp;efficient&nbsp;attention&nbsp;and&nbsp;sliced&nbsp;attention&nbsp;are&nbsp;both&nbsp;enabled,&nbsp;memory&nbsp;efficient&nbsp;attention&nbsp;takes<br>
precedent.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;attention_op&nbsp;(`Callable`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Override&nbsp;the&nbsp;default&nbsp;`None`&nbsp;operator&nbsp;for&nbsp;use&nbsp;as&nbsp;`op`&nbsp;argument&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[`memory_efficient_attention()`](<a href="https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention">https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention</a>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;function&nbsp;of&nbsp;xFormers.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```py<br>
&gt;&gt;&gt;&nbsp;import&nbsp;torch<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;DiffusionPipeline<br>
&gt;&gt;&gt;&nbsp;from&nbsp;xformers.ops&nbsp;import&nbsp;MemoryEfficientAttentionFlashAttentionOp<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;pipe&nbsp;=&nbsp;DiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("stabilityai/stable-diffusion-2-1",&nbsp;torch_dtype=torch.float16)<br>
&gt;&gt;&gt;&nbsp;pipe&nbsp;=&nbsp;pipe.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>("cuda")<br>
&gt;&gt;&gt;&nbsp;pipe.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-enable_xformers_memory_efficient_attention">enable_xformers_memory_efficient_attention</a>(attention_op=MemoryEfficientAttentionFlashAttentionOp)<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Workaround&nbsp;for&nbsp;not&nbsp;accepting&nbsp;attention&nbsp;shape&nbsp;using&nbsp;VAE&nbsp;for&nbsp;Flash&nbsp;Attention<br>
&gt;&gt;&gt;&nbsp;pipe.vae.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-enable_xformers_memory_efficient_attention">enable_xformers_memory_efficient_attention</a>(attention_op=None)<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-maybe_free_model_hooks"><strong>maybe_free_model_hooks</strong></a>(self)</dt><dd><tt>Function&nbsp;that&nbsp;offloads&nbsp;all&nbsp;components,&nbsp;removes&nbsp;all&nbsp;model&nbsp;hooks&nbsp;that&nbsp;were&nbsp;added&nbsp;when&nbsp;using<br>
`enable_model_cpu_offload`&nbsp;and&nbsp;then&nbsp;applies&nbsp;them&nbsp;again.&nbsp;In&nbsp;case&nbsp;the&nbsp;model&nbsp;has&nbsp;not&nbsp;been&nbsp;offloaded&nbsp;this&nbsp;function<br>
is&nbsp;a&nbsp;no-op.&nbsp;Make&nbsp;sure&nbsp;to&nbsp;add&nbsp;this&nbsp;function&nbsp;to&nbsp;the&nbsp;end&nbsp;of&nbsp;the&nbsp;`__call__`&nbsp;function&nbsp;of&nbsp;your&nbsp;pipeline&nbsp;so&nbsp;that&nbsp;it<br>
functions&nbsp;correctly&nbsp;when&nbsp;applying&nbsp;enable_model_cpu_offload.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-progress_bar"><strong>progress_bar</strong></a>(self, iterable=None, total=None)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-register_modules"><strong>register_modules</strong></a>(self, **kwargs)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-remove_all_hooks"><strong>remove_all_hooks</strong></a>(self)</dt><dd><tt>Removes&nbsp;all&nbsp;hooks&nbsp;that&nbsp;were&nbsp;added&nbsp;when&nbsp;using&nbsp;`enable_sequential_cpu_offload`&nbsp;or&nbsp;`enable_model_cpu_offload`.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-reset_device_map"><strong>reset_device_map</strong></a>(self)</dt><dd><tt>Resets&nbsp;the&nbsp;device&nbsp;maps&nbsp;(if&nbsp;any)&nbsp;to&nbsp;None.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-save_pretrained"><strong>save_pretrained</strong></a>(self, save_directory: Union[str, os.PathLike], safe_serialization: bool = True, variant: Optional[str] = None, push_to_hub: bool = False, **kwargs)</dt><dd><tt>Save&nbsp;all&nbsp;saveable&nbsp;variables&nbsp;of&nbsp;the&nbsp;pipeline&nbsp;to&nbsp;a&nbsp;directory.&nbsp;A&nbsp;pipeline&nbsp;variable&nbsp;can&nbsp;be&nbsp;saved&nbsp;and&nbsp;loaded&nbsp;if&nbsp;its<br>
class&nbsp;implements&nbsp;both&nbsp;a&nbsp;save&nbsp;and&nbsp;loading&nbsp;method.&nbsp;The&nbsp;pipeline&nbsp;is&nbsp;easily&nbsp;reloaded&nbsp;using&nbsp;the<br>
[`~DiffusionPipeline.from_pretrained`]&nbsp;class&nbsp;method.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_directory&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Directory&nbsp;to&nbsp;save&nbsp;a&nbsp;pipeline&nbsp;to.&nbsp;Will&nbsp;be&nbsp;created&nbsp;if&nbsp;it&nbsp;doesn't&nbsp;exist.<br>
&nbsp;&nbsp;&nbsp;&nbsp;safe_serialization&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;model&nbsp;using&nbsp;`safetensors`&nbsp;or&nbsp;the&nbsp;traditional&nbsp;PyTorch&nbsp;way&nbsp;with&nbsp;`pickle`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;variant&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;specified,&nbsp;weights&nbsp;are&nbsp;saved&nbsp;in&nbsp;the&nbsp;format&nbsp;`pytorch_model.&lt;variant&gt;.bin`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;push_to_hub&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;push&nbsp;your&nbsp;model&nbsp;to&nbsp;the&nbsp;Hugging&nbsp;Face&nbsp;model&nbsp;hub&nbsp;after&nbsp;saving&nbsp;it.&nbsp;You&nbsp;can&nbsp;specify&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;repository&nbsp;you&nbsp;want&nbsp;to&nbsp;push&nbsp;to&nbsp;with&nbsp;`repo_id`&nbsp;(will&nbsp;default&nbsp;to&nbsp;the&nbsp;name&nbsp;of&nbsp;`save_directory`&nbsp;in&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;namespace).<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs&nbsp;(`Dict[str,&nbsp;Any]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;passed&nbsp;along&nbsp;to&nbsp;the&nbsp;[`~utils.PushToHubMixin.push_to_hub`]&nbsp;method.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-set_attention_slice"><strong>set_attention_slice</strong></a>(self, slice_size: Optional[int])</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-set_progress_bar_config"><strong>set_progress_bar_config</strong></a>(self, **kwargs)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-set_use_memory_efficient_attention_xformers"><strong>set_use_memory_efficient_attention_xformers</strong></a>(self, valid: bool, attention_op: Optional[Callable] = None) -&gt; None</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Performs&nbsp;Pipeline&nbsp;dtype&nbsp;and/or&nbsp;device&nbsp;conversion.&nbsp;A&nbsp;torch.dtype&nbsp;and&nbsp;torch.device&nbsp;are&nbsp;inferred&nbsp;from&nbsp;the<br>
arguments&nbsp;of&nbsp;`self.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>(*args,&nbsp;**kwargs).`<br>
&nbsp;<br>
&lt;Tip&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;the&nbsp;pipeline&nbsp;already&nbsp;has&nbsp;the&nbsp;correct&nbsp;torch.dtype&nbsp;and&nbsp;torch.device,&nbsp;then&nbsp;it&nbsp;is&nbsp;returned&nbsp;as&nbsp;is.&nbsp;Otherwise,<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;returned&nbsp;pipeline&nbsp;is&nbsp;a&nbsp;copy&nbsp;of&nbsp;self&nbsp;with&nbsp;the&nbsp;desired&nbsp;torch.dtype&nbsp;and&nbsp;torch.device.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
&nbsp;<br>
Here&nbsp;are&nbsp;the&nbsp;ways&nbsp;to&nbsp;call&nbsp;`to`:<br>
&nbsp;<br>
-&nbsp;`<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>(dtype,&nbsp;silence_dtype_warnings=False)&nbsp;‚Üí&nbsp;DiffusionPipeline`&nbsp;to&nbsp;return&nbsp;a&nbsp;pipeline&nbsp;with&nbsp;the&nbsp;specified<br>
&nbsp;&nbsp;[`dtype`](<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype">https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype</a>)<br>
-&nbsp;`<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>(device,&nbsp;silence_dtype_warnings=False)&nbsp;‚Üí&nbsp;DiffusionPipeline`&nbsp;to&nbsp;return&nbsp;a&nbsp;pipeline&nbsp;with&nbsp;the&nbsp;specified<br>
&nbsp;&nbsp;[`device`](<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device">https://pytorch.org/docs/stable/tensor_attributes.html#torch.device</a>)<br>
-&nbsp;`<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;silence_dtype_warnings=False)&nbsp;‚Üí&nbsp;DiffusionPipeline`&nbsp;to&nbsp;return&nbsp;a&nbsp;pipeline&nbsp;with&nbsp;the<br>
&nbsp;&nbsp;specified&nbsp;[`device`](<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device">https://pytorch.org/docs/stable/tensor_attributes.html#torch.device</a>)&nbsp;and<br>
&nbsp;&nbsp;[`dtype`](<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype">https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype</a>)<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(`torch.dtype`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns&nbsp;a&nbsp;pipeline&nbsp;with&nbsp;the&nbsp;specified<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[`dtype`](<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype">https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype</a>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(`torch.Device`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns&nbsp;a&nbsp;pipeline&nbsp;with&nbsp;the&nbsp;specified<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[`device`](<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device">https://pytorch.org/docs/stable/tensor_attributes.html#torch.device</a>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;silence_dtype_warnings&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;omit&nbsp;warnings&nbsp;if&nbsp;the&nbsp;target&nbsp;`dtype`&nbsp;is&nbsp;not&nbsp;compatible&nbsp;with&nbsp;the&nbsp;target&nbsp;`device`.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;[`DiffusionPipeline`]:&nbsp;The&nbsp;pipeline&nbsp;converted&nbsp;to&nbsp;specified&nbsp;`dtype`&nbsp;and/or&nbsp;`dtype`.</tt></dd></dl>

<hr>
Class methods inherited from <a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-download"><strong>download</strong></a>(pretrained_model_name, **kwargs) -&gt; Union[str, os.PathLike]<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Download&nbsp;and&nbsp;cache&nbsp;a&nbsp;PyTorch&nbsp;diffusion&nbsp;pipeline&nbsp;from&nbsp;pretrained&nbsp;pipeline&nbsp;weights.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;string,&nbsp;the&nbsp;*repository&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`CompVis/ldm-text2im-large-256`)&nbsp;of&nbsp;a&nbsp;pretrained&nbsp;pipeline<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hosted&nbsp;on&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_pipeline&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*repository&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`CompVis/ldm-text2im-large-256`)&nbsp;of&nbsp;a&nbsp;pretrained<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pipeline&nbsp;hosted&nbsp;on&nbsp;the&nbsp;Hub.&nbsp;The&nbsp;repository&nbsp;must&nbsp;contain&nbsp;a&nbsp;file&nbsp;called&nbsp;`pipeline.py`&nbsp;that&nbsp;defines<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;custom&nbsp;pipeline.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*file&nbsp;name*&nbsp;of&nbsp;a&nbsp;community&nbsp;pipeline&nbsp;hosted&nbsp;on&nbsp;GitHub&nbsp;under<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Community](<a href="https://github.com/huggingface/diffusers/tree/main/examples/community">https://github.com/huggingface/diffusers/tree/main/examples/community</a>).&nbsp;Valid&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names&nbsp;must&nbsp;match&nbsp;the&nbsp;file&nbsp;name&nbsp;and&nbsp;not&nbsp;the&nbsp;pipeline&nbsp;script&nbsp;(`clip_guided_stable_diffusion`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;`clip_guided_stable_diffusion.py`).&nbsp;Community&nbsp;pipelines&nbsp;are&nbsp;always&nbsp;loaded&nbsp;from&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current&nbsp;`main`&nbsp;branch&nbsp;of&nbsp;GitHub.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(`./my_pipeline_directory/`)&nbsp;containing&nbsp;a&nbsp;custom&nbsp;pipeline.&nbsp;The&nbsp;directory<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;must&nbsp;contain&nbsp;a&nbsp;file&nbsp;called&nbsp;`pipeline.py`&nbsp;that&nbsp;defines&nbsp;the&nbsp;custom&nbsp;pipeline.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üß™&nbsp;This&nbsp;is&nbsp;an&nbsp;experimental&nbsp;feature&nbsp;and&nbsp;may&nbsp;change&nbsp;in&nbsp;the&nbsp;future.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/Tip&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;more&nbsp;information&nbsp;on&nbsp;how&nbsp;to&nbsp;load&nbsp;and&nbsp;create&nbsp;custom&nbsp;pipelines,&nbsp;take&nbsp;a&nbsp;look&nbsp;at&nbsp;[How&nbsp;to&nbsp;contribute&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;community&nbsp;pipeline](<a href="https://huggingface.co/docs/diffusers/main/en/using-diffusers/contribute_pipeline">https://huggingface.co/docs/diffusers/main/en/using-diffusers/contribute_pipeline</a>).<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_loading_info(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;also&nbsp;return&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;missing&nbsp;keys,&nbsp;unexpected&nbsp;keys&nbsp;and&nbsp;error&nbsp;messages.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;or&nbsp;a&nbsp;commit&nbsp;id&nbsp;similar&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`revision`&nbsp;when&nbsp;loading&nbsp;a&nbsp;custom&nbsp;pipeline&nbsp;from&nbsp;the&nbsp;Hub.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;ü§ó&nbsp;Diffusers&nbsp;version&nbsp;when&nbsp;loading&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;custom&nbsp;pipeline&nbsp;from&nbsp;GitHub,&nbsp;otherwise&nbsp;it&nbsp;defaults&nbsp;to&nbsp;`"main"`&nbsp;when&nbsp;loading&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;mirror&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mirror&nbsp;source&nbsp;to&nbsp;resolve&nbsp;accessibility&nbsp;issues&nbsp;if&nbsp;you're&nbsp;downloading&nbsp;a&nbsp;model&nbsp;in&nbsp;China.&nbsp;We&nbsp;do&nbsp;not<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;guarantee&nbsp;the&nbsp;timeliness&nbsp;or&nbsp;safety&nbsp;of&nbsp;the&nbsp;source,&nbsp;and&nbsp;you&nbsp;should&nbsp;refer&nbsp;to&nbsp;the&nbsp;mirror&nbsp;site&nbsp;for&nbsp;more<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;information.<br>
&nbsp;&nbsp;&nbsp;&nbsp;variant&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Load&nbsp;weights&nbsp;from&nbsp;a&nbsp;specified&nbsp;variant&nbsp;filename&nbsp;such&nbsp;as&nbsp;`"fp16"`&nbsp;or&nbsp;`"ema"`.&nbsp;This&nbsp;is&nbsp;ignored&nbsp;when<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading&nbsp;`from_flax`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;use_safetensors&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`None`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;set&nbsp;to&nbsp;`None`,&nbsp;the&nbsp;safetensors&nbsp;weights&nbsp;are&nbsp;downloaded&nbsp;if&nbsp;they're&nbsp;available&nbsp;**and**&nbsp;if&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;safetensors&nbsp;library&nbsp;is&nbsp;installed.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model&nbsp;is&nbsp;forcibly&nbsp;loaded&nbsp;from&nbsp;safetensors<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights.&nbsp;If&nbsp;set&nbsp;to&nbsp;`False`,&nbsp;safetensors&nbsp;weights&nbsp;are&nbsp;not&nbsp;loaded.<br>
&nbsp;&nbsp;&nbsp;&nbsp;use_onnx&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;ONNX&nbsp;weights&nbsp;will&nbsp;always&nbsp;be&nbsp;downloaded&nbsp;if&nbsp;present.&nbsp;If&nbsp;set&nbsp;to&nbsp;`False`,&nbsp;ONNX&nbsp;weights<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;never&nbsp;be&nbsp;downloaded.&nbsp;By&nbsp;default&nbsp;`use_onnx`&nbsp;defaults&nbsp;to&nbsp;the&nbsp;`_is_onnx`&nbsp;class&nbsp;attribute&nbsp;which&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`False`&nbsp;for&nbsp;non-ONNX&nbsp;pipelines&nbsp;and&nbsp;`True`&nbsp;for&nbsp;ONNX&nbsp;pipelines.&nbsp;ONNX&nbsp;weights&nbsp;include&nbsp;both&nbsp;files&nbsp;ending<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;`.onnx`&nbsp;and&nbsp;`.pb`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;trust_remote_code&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;allow&nbsp;for&nbsp;custom&nbsp;pipelines&nbsp;and&nbsp;components&nbsp;defined&nbsp;on&nbsp;the&nbsp;Hub&nbsp;in&nbsp;their&nbsp;own&nbsp;files.&nbsp;This<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;option&nbsp;should&nbsp;only&nbsp;be&nbsp;set&nbsp;to&nbsp;`True`&nbsp;for&nbsp;repositories&nbsp;you&nbsp;trust&nbsp;and&nbsp;in&nbsp;which&nbsp;you&nbsp;have&nbsp;read&nbsp;the&nbsp;code,&nbsp;as<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;it&nbsp;will&nbsp;execute&nbsp;code&nbsp;present&nbsp;on&nbsp;the&nbsp;Hub&nbsp;on&nbsp;your&nbsp;local&nbsp;machine.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`os.PathLike`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;path&nbsp;to&nbsp;the&nbsp;downloaded&nbsp;pipeline.<br>
&nbsp;<br>
&lt;Tip&gt;<br>
&nbsp;<br>
To&nbsp;use&nbsp;private&nbsp;or&nbsp;[gated&nbsp;models](<a href="https://huggingface.co/docs/hub/models-gated#gated-models">https://huggingface.co/docs/hub/models-gated#gated-models</a>),&nbsp;log-in&nbsp;with<br>
`huggingface-cli&nbsp;login`.<br>
&nbsp;<br>
&lt;/Tip&gt;</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-from_pipe"><strong>from_pipe</strong></a>(pipeline, **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Create&nbsp;a&nbsp;new&nbsp;pipeline&nbsp;from&nbsp;a&nbsp;given&nbsp;pipeline.&nbsp;This&nbsp;method&nbsp;is&nbsp;useful&nbsp;to&nbsp;create&nbsp;a&nbsp;new&nbsp;pipeline&nbsp;from&nbsp;the&nbsp;existing<br>
pipeline&nbsp;components&nbsp;without&nbsp;reallocating&nbsp;additional&nbsp;memory.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pipeline&nbsp;(`DiffusionPipeline`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;pipeline&nbsp;from&nbsp;which&nbsp;to&nbsp;create&nbsp;a&nbsp;new&nbsp;pipeline.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`DiffusionPipeline`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;new&nbsp;pipeline&nbsp;with&nbsp;the&nbsp;same&nbsp;weights&nbsp;and&nbsp;configurations&nbsp;as&nbsp;`pipeline`.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```py<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;StableDiffusionPipeline,&nbsp;StableDiffusionSAGPipeline<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;pipe&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("runwayml/stable-diffusion-v1-5")<br>
&gt;&gt;&gt;&nbsp;new_pipe&nbsp;=&nbsp;StableDiffusionSAGPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pipe">from_pipe</a>(pipe)<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained"><strong>from_pretrained</strong></a>(pretrained_model_name_or_path: Union[str, os.PathLike, NoneType], **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Instantiate&nbsp;a&nbsp;PyTorch&nbsp;diffusion&nbsp;pipeline&nbsp;from&nbsp;pretrained&nbsp;pipeline&nbsp;weights.<br>
&nbsp;<br>
The&nbsp;pipeline&nbsp;is&nbsp;set&nbsp;in&nbsp;evaluation&nbsp;mode&nbsp;(`model.eval()`)&nbsp;by&nbsp;default.<br>
&nbsp;<br>
If&nbsp;you&nbsp;get&nbsp;the&nbsp;error&nbsp;message&nbsp;below,&nbsp;you&nbsp;need&nbsp;to&nbsp;finetune&nbsp;the&nbsp;weights&nbsp;for&nbsp;your&nbsp;downstream&nbsp;task:<br>
&nbsp;<br>
```<br>
Some&nbsp;weights&nbsp;of&nbsp;UNet2DConditionModel&nbsp;were&nbsp;not&nbsp;initialized&nbsp;from&nbsp;the&nbsp;model&nbsp;checkpoint&nbsp;at&nbsp;runwayml/stable-diffusion-v1-5&nbsp;and&nbsp;are&nbsp;newly&nbsp;initialized&nbsp;because&nbsp;the&nbsp;shapes&nbsp;did&nbsp;not&nbsp;match:<br>
-&nbsp;conv_in.weight:&nbsp;found&nbsp;shape&nbsp;torch.Size([320,&nbsp;4,&nbsp;3,&nbsp;3])&nbsp;in&nbsp;the&nbsp;checkpoint&nbsp;and&nbsp;torch.Size([320,&nbsp;9,&nbsp;3,&nbsp;3])&nbsp;in&nbsp;the&nbsp;model&nbsp;instantiated<br>
You&nbsp;should&nbsp;probably&nbsp;TRAIN&nbsp;this&nbsp;model&nbsp;on&nbsp;a&nbsp;down-stream&nbsp;task&nbsp;to&nbsp;be&nbsp;able&nbsp;to&nbsp;use&nbsp;it&nbsp;for&nbsp;predictions&nbsp;and&nbsp;inference.<br>
```<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name_or_path&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*repo&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`CompVis/ldm-text2im-large-256`)&nbsp;of&nbsp;a&nbsp;pretrained&nbsp;pipeline<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hosted&nbsp;on&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(for&nbsp;example&nbsp;`./my_pipeline_directory/`)&nbsp;containing&nbsp;pipeline&nbsp;weights<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;saved&nbsp;using<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[`~DiffusionPipeline.save_pretrained`].<br>
&nbsp;&nbsp;&nbsp;&nbsp;torch_dtype&nbsp;(`str`&nbsp;or&nbsp;`torch.dtype`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Override&nbsp;the&nbsp;default&nbsp;`torch.dtype`&nbsp;and&nbsp;load&nbsp;the&nbsp;model&nbsp;with&nbsp;another&nbsp;dtype.&nbsp;If&nbsp;"auto"&nbsp;is&nbsp;passed,&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;is&nbsp;automatically&nbsp;derived&nbsp;from&nbsp;the&nbsp;model's&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_pipeline&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üß™&nbsp;This&nbsp;is&nbsp;an&nbsp;experimental&nbsp;feature&nbsp;and&nbsp;may&nbsp;change&nbsp;in&nbsp;the&nbsp;future.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/Tip&gt;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*repo&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`hf-internal-testing/diffusers-dummy-pipeline`)&nbsp;of&nbsp;a&nbsp;custom<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pipeline&nbsp;hosted&nbsp;on&nbsp;the&nbsp;Hub.&nbsp;The&nbsp;repository&nbsp;must&nbsp;contain&nbsp;a&nbsp;file&nbsp;called&nbsp;pipeline.py&nbsp;that&nbsp;defines<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;custom&nbsp;pipeline.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*file&nbsp;name*&nbsp;of&nbsp;a&nbsp;community&nbsp;pipeline&nbsp;hosted&nbsp;on&nbsp;GitHub&nbsp;under<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Community](<a href="https://github.com/huggingface/diffusers/tree/main/examples/community">https://github.com/huggingface/diffusers/tree/main/examples/community</a>).&nbsp;Valid&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names&nbsp;must&nbsp;match&nbsp;the&nbsp;file&nbsp;name&nbsp;and&nbsp;not&nbsp;the&nbsp;pipeline&nbsp;script&nbsp;(`clip_guided_stable_diffusion`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;`clip_guided_stable_diffusion.py`).&nbsp;Community&nbsp;pipelines&nbsp;are&nbsp;always&nbsp;loaded&nbsp;from&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current&nbsp;main&nbsp;branch&nbsp;of&nbsp;GitHub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;directory&nbsp;(`./my_pipeline_directory/`)&nbsp;containing&nbsp;a&nbsp;custom&nbsp;pipeline.&nbsp;The&nbsp;directory<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;must&nbsp;contain&nbsp;a&nbsp;file&nbsp;called&nbsp;`pipeline.py`&nbsp;that&nbsp;defines&nbsp;the&nbsp;custom&nbsp;pipeline.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;more&nbsp;information&nbsp;on&nbsp;how&nbsp;to&nbsp;load&nbsp;and&nbsp;create&nbsp;custom&nbsp;pipelines,&nbsp;please&nbsp;have&nbsp;a&nbsp;look&nbsp;at&nbsp;[Loading&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adding&nbsp;Custom<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pipelines](<a href="https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview">https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview</a>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cache_dir&nbsp;(`Union[str,&nbsp;os.PathLike]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;a&nbsp;directory&nbsp;where&nbsp;a&nbsp;downloaded&nbsp;pretrained&nbsp;model&nbsp;configuration&nbsp;is&nbsp;cached&nbsp;if&nbsp;the&nbsp;standard&nbsp;cache<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;not&nbsp;used.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_loading_info(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;also&nbsp;return&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;missing&nbsp;keys,&nbsp;unexpected&nbsp;keys&nbsp;and&nbsp;error&nbsp;messages.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;custom_revision&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;or&nbsp;a&nbsp;commit&nbsp;id&nbsp;similar&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`revision`&nbsp;when&nbsp;loading&nbsp;a&nbsp;custom&nbsp;pipeline&nbsp;from&nbsp;the&nbsp;Hub.&nbsp;Defaults&nbsp;to&nbsp;the&nbsp;latest&nbsp;stable&nbsp;ü§ó&nbsp;Diffusers<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;version.<br>
&nbsp;&nbsp;&nbsp;&nbsp;mirror&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mirror&nbsp;source&nbsp;to&nbsp;resolve&nbsp;accessibility&nbsp;issues&nbsp;if&nbsp;you‚Äôre&nbsp;downloading&nbsp;a&nbsp;model&nbsp;in&nbsp;China.&nbsp;We&nbsp;do&nbsp;not<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;guarantee&nbsp;the&nbsp;timeliness&nbsp;or&nbsp;safety&nbsp;of&nbsp;the&nbsp;source,&nbsp;and&nbsp;you&nbsp;should&nbsp;refer&nbsp;to&nbsp;the&nbsp;mirror&nbsp;site&nbsp;for&nbsp;more<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;information.<br>
&nbsp;&nbsp;&nbsp;&nbsp;device_map&nbsp;(`str`&nbsp;or&nbsp;`Dict[str,&nbsp;Union[int,&nbsp;str,&nbsp;torch.device]]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;map&nbsp;that&nbsp;specifies&nbsp;where&nbsp;each&nbsp;submodule&nbsp;should&nbsp;go.&nbsp;It&nbsp;doesn‚Äôt&nbsp;need&nbsp;to&nbsp;be&nbsp;defined&nbsp;for&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;parameter/buffer&nbsp;name;&nbsp;once&nbsp;a&nbsp;given&nbsp;module&nbsp;name&nbsp;is&nbsp;inside,&nbsp;every&nbsp;submodule&nbsp;of&nbsp;it&nbsp;will&nbsp;be&nbsp;sent&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;same&nbsp;device.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set&nbsp;`device_map="auto"`&nbsp;to&nbsp;have&nbsp;ü§ó&nbsp;Accelerate&nbsp;automatically&nbsp;compute&nbsp;the&nbsp;most&nbsp;optimized&nbsp;`device_map`.&nbsp;For<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;more&nbsp;information&nbsp;about&nbsp;each&nbsp;option&nbsp;see&nbsp;[designing&nbsp;a&nbsp;device<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map](<a href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map">https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map</a>).<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_memory&nbsp;(`Dict`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;device&nbsp;identifier&nbsp;for&nbsp;the&nbsp;maximum&nbsp;memory.&nbsp;Will&nbsp;default&nbsp;to&nbsp;the&nbsp;maximum&nbsp;memory&nbsp;available&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;each&nbsp;GPU&nbsp;and&nbsp;the&nbsp;available&nbsp;CPU&nbsp;RAM&nbsp;if&nbsp;unset.<br>
&nbsp;&nbsp;&nbsp;&nbsp;offload_folder&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;path&nbsp;to&nbsp;offload&nbsp;weights&nbsp;if&nbsp;device_map&nbsp;contains&nbsp;the&nbsp;value&nbsp;`"disk"`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;offload_state_dict&nbsp;(`bool`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;`True`,&nbsp;temporarily&nbsp;offloads&nbsp;the&nbsp;CPU&nbsp;state&nbsp;dict&nbsp;to&nbsp;the&nbsp;hard&nbsp;drive&nbsp;to&nbsp;avoid&nbsp;running&nbsp;out&nbsp;of&nbsp;CPU&nbsp;RAM&nbsp;if<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;weight&nbsp;of&nbsp;the&nbsp;CPU&nbsp;state&nbsp;dict&nbsp;+&nbsp;the&nbsp;biggest&nbsp;shard&nbsp;of&nbsp;the&nbsp;checkpoint&nbsp;does&nbsp;not&nbsp;fit.&nbsp;Defaults&nbsp;to&nbsp;`True`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;when&nbsp;there&nbsp;is&nbsp;some&nbsp;disk&nbsp;offload.<br>
&nbsp;&nbsp;&nbsp;&nbsp;low_cpu_mem_usage&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`&nbsp;if&nbsp;torch&nbsp;version&nbsp;&gt;=&nbsp;1.9.0&nbsp;else&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Speed&nbsp;up&nbsp;model&nbsp;loading&nbsp;only&nbsp;loading&nbsp;the&nbsp;pretrained&nbsp;weights&nbsp;and&nbsp;not&nbsp;initializing&nbsp;the&nbsp;weights.&nbsp;This&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tries&nbsp;to&nbsp;not&nbsp;use&nbsp;more&nbsp;than&nbsp;1x&nbsp;model&nbsp;size&nbsp;in&nbsp;CPU&nbsp;memory&nbsp;(including&nbsp;peak&nbsp;memory)&nbsp;while&nbsp;loading&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Only&nbsp;supported&nbsp;for&nbsp;PyTorch&nbsp;&gt;=&nbsp;1.9.0.&nbsp;If&nbsp;you&nbsp;are&nbsp;using&nbsp;an&nbsp;older&nbsp;version&nbsp;of&nbsp;PyTorch,&nbsp;setting&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;argument&nbsp;to&nbsp;`True`&nbsp;will&nbsp;raise&nbsp;an&nbsp;error.<br>
&nbsp;&nbsp;&nbsp;&nbsp;use_safetensors&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`None`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;set&nbsp;to&nbsp;`None`,&nbsp;the&nbsp;safetensors&nbsp;weights&nbsp;are&nbsp;downloaded&nbsp;if&nbsp;they're&nbsp;available&nbsp;**and**&nbsp;if&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;safetensors&nbsp;library&nbsp;is&nbsp;installed.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model&nbsp;is&nbsp;forcibly&nbsp;loaded&nbsp;from&nbsp;safetensors<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights.&nbsp;If&nbsp;set&nbsp;to&nbsp;`False`,&nbsp;safetensors&nbsp;weights&nbsp;are&nbsp;not&nbsp;loaded.<br>
&nbsp;&nbsp;&nbsp;&nbsp;use_onnx&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`None`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;ONNX&nbsp;weights&nbsp;will&nbsp;always&nbsp;be&nbsp;downloaded&nbsp;if&nbsp;present.&nbsp;If&nbsp;set&nbsp;to&nbsp;`False`,&nbsp;ONNX&nbsp;weights<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;never&nbsp;be&nbsp;downloaded.&nbsp;By&nbsp;default&nbsp;`use_onnx`&nbsp;defaults&nbsp;to&nbsp;the&nbsp;`_is_onnx`&nbsp;class&nbsp;attribute&nbsp;which&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`False`&nbsp;for&nbsp;non-ONNX&nbsp;pipelines&nbsp;and&nbsp;`True`&nbsp;for&nbsp;ONNX&nbsp;pipelines.&nbsp;ONNX&nbsp;weights&nbsp;include&nbsp;both&nbsp;files&nbsp;ending<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;`.onnx`&nbsp;and&nbsp;`.pb`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs&nbsp;(remaining&nbsp;dictionary&nbsp;of&nbsp;keyword&nbsp;arguments,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;overwrite&nbsp;load&nbsp;and&nbsp;saveable&nbsp;variables&nbsp;(the&nbsp;pipeline&nbsp;components&nbsp;of&nbsp;the&nbsp;specific&nbsp;pipeline<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class).&nbsp;The&nbsp;overwritten&nbsp;components&nbsp;are&nbsp;passed&nbsp;directly&nbsp;to&nbsp;the&nbsp;pipelines&nbsp;`__init__`&nbsp;method.&nbsp;See&nbsp;example<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;below&nbsp;for&nbsp;more&nbsp;information.<br>
&nbsp;&nbsp;&nbsp;&nbsp;variant&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Load&nbsp;weights&nbsp;from&nbsp;a&nbsp;specified&nbsp;variant&nbsp;filename&nbsp;such&nbsp;as&nbsp;`"fp16"`&nbsp;or&nbsp;`"ema"`.&nbsp;This&nbsp;is&nbsp;ignored&nbsp;when<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading&nbsp;`from_flax`.<br>
&nbsp;<br>
&lt;Tip&gt;<br>
&nbsp;<br>
To&nbsp;use&nbsp;private&nbsp;or&nbsp;[gated](<a href="https://huggingface.co/docs/hub/models-gated#gated-models">https://huggingface.co/docs/hub/models-gated#gated-models</a>)&nbsp;models,&nbsp;log-in&nbsp;with<br>
`huggingface-cli&nbsp;login`.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```py<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;DiffusionPipeline<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Download&nbsp;pipeline&nbsp;from&nbsp;huggingface.co&nbsp;and&nbsp;cache.<br>
&gt;&gt;&gt;&nbsp;pipeline&nbsp;=&nbsp;DiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("CompVis/ldm-text2im-large-256")<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Download&nbsp;pipeline&nbsp;that&nbsp;requires&nbsp;an&nbsp;authorization&nbsp;token<br>
&gt;&gt;&gt;&nbsp;#&nbsp;For&nbsp;more&nbsp;information&nbsp;on&nbsp;access&nbsp;tokens,&nbsp;please&nbsp;refer&nbsp;to&nbsp;this&nbsp;section<br>
&gt;&gt;&gt;&nbsp;#&nbsp;of&nbsp;the&nbsp;documentation](<a href="https://huggingface.co/docs/hub/security-tokens">https://huggingface.co/docs/hub/security-tokens</a>)<br>
&gt;&gt;&gt;&nbsp;pipeline&nbsp;=&nbsp;DiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("runwayml/stable-diffusion-v1-5")<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Use&nbsp;a&nbsp;different&nbsp;scheduler<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;LMSDiscreteScheduler<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;scheduler&nbsp;=&nbsp;LMSDiscreteScheduler.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_config">from_config</a>(pipeline.scheduler.config)<br>
&gt;&gt;&gt;&nbsp;pipeline.scheduler&nbsp;=&nbsp;scheduler<br>
```</tt></dd></dl>

<hr>
Static methods inherited from <a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-numpy_to_pil"><strong>numpy_to_pil</strong></a>(images)</dt><dd><tt>Convert&nbsp;a&nbsp;NumPy&nbsp;image&nbsp;or&nbsp;a&nbsp;batch&nbsp;of&nbsp;images&nbsp;to&nbsp;a&nbsp;PIL&nbsp;image.</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a>:<br>
<dl><dt><strong>components</strong></dt>
<dd><tt>The&nbsp;`self.<strong>components</strong>`&nbsp;property&nbsp;can&nbsp;be&nbsp;useful&nbsp;to&nbsp;run&nbsp;different&nbsp;pipelines&nbsp;with&nbsp;the&nbsp;same&nbsp;weights&nbsp;and<br>
configurations&nbsp;without&nbsp;reallocating&nbsp;additional&nbsp;memory.<br>
&nbsp;<br>
Returns&nbsp;(`dict`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;containing&nbsp;all&nbsp;the&nbsp;modules&nbsp;needed&nbsp;to&nbsp;initialize&nbsp;the&nbsp;pipeline.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```py<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;(<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;StableDiffusionPipeline,<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;StableDiffusionImg2ImgPipeline,<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;StableDiffusionInpaintPipeline,<br>
...&nbsp;)<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;text2img&nbsp;=&nbsp;StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")<br>
&gt;&gt;&gt;&nbsp;img2img&nbsp;=&nbsp;StableDiffusionImg2ImgPipeline(**text2img.components)<br>
&gt;&gt;&gt;&nbsp;inpaint&nbsp;=&nbsp;StableDiffusionInpaintPipeline(**text2img.components)<br>
```</tt></dd>
</dl>
<dl><dt><strong>device</strong></dt>
<dd><tt>Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`torch.device`:&nbsp;The&nbsp;torch&nbsp;device&nbsp;on&nbsp;which&nbsp;the&nbsp;pipeline&nbsp;is&nbsp;located.</tt></dd>
</dl>
<dl><dt><strong>dtype</strong></dt>
<dd><tt>Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`torch.dtype`:&nbsp;The&nbsp;torch&nbsp;dtype&nbsp;on&nbsp;which&nbsp;the&nbsp;pipeline&nbsp;is&nbsp;located.</tt></dd>
</dl>
<dl><dt><strong>name_or_path</strong></dt>
</dl>
<hr>
Data and other attributes inherited from <a href="diffusers.pipelines.pipeline_utils.html#DiffusionPipeline">diffusers.pipelines.pipeline_utils.DiffusionPipeline</a>:<br>
<dl><dt><strong>config_name</strong> = 'model_index.json'</dl>

<dl><dt><strong>hf_device_map</strong> = None</dl>

<hr>
Methods inherited from <a href="diffusers.configuration_utils.html#ConfigMixin">diffusers.configuration_utils.ConfigMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-__getattr__"><strong>__getattr__</strong></a>(self, name: str) -&gt; Any</dt><dd><tt>The&nbsp;only&nbsp;reason&nbsp;we&nbsp;overwrite&nbsp;`getattr`&nbsp;here&nbsp;is&nbsp;to&nbsp;gracefully&nbsp;deprecate&nbsp;accessing<br>
config&nbsp;attributes&nbsp;directly.&nbsp;See&nbsp;<a href="https://github.com/huggingface/diffusers/pull/3129">https://github.com/huggingface/diffusers/pull/3129</a><br>
&nbsp;<br>
This&nbsp;function&nbsp;is&nbsp;mostly&nbsp;copied&nbsp;from&nbsp;PyTorch's&nbsp;__getattr__&nbsp;overwrite:<br>
<a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module">https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module</a></tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-register_to_config"><strong>register_to_config</strong></a>(self, **kwargs)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-save_config"><strong>save_config</strong></a>(self, save_directory: Union[str, os.PathLike], push_to_hub: bool = False, **kwargs)</dt><dd><tt>Save&nbsp;a&nbsp;configuration&nbsp;object&nbsp;to&nbsp;the&nbsp;directory&nbsp;specified&nbsp;in&nbsp;`save_directory`&nbsp;so&nbsp;that&nbsp;it&nbsp;can&nbsp;be&nbsp;reloaded&nbsp;using&nbsp;the<br>
[`~ConfigMixin.from_config`]&nbsp;class&nbsp;method.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_directory&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Directory&nbsp;where&nbsp;the&nbsp;configuration&nbsp;JSON&nbsp;file&nbsp;is&nbsp;saved&nbsp;(will&nbsp;be&nbsp;created&nbsp;if&nbsp;it&nbsp;does&nbsp;not&nbsp;exist).<br>
&nbsp;&nbsp;&nbsp;&nbsp;push_to_hub&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;push&nbsp;your&nbsp;model&nbsp;to&nbsp;the&nbsp;Hugging&nbsp;Face&nbsp;Hub&nbsp;after&nbsp;saving&nbsp;it.&nbsp;You&nbsp;can&nbsp;specify&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;repository&nbsp;you&nbsp;want&nbsp;to&nbsp;push&nbsp;to&nbsp;with&nbsp;`repo_id`&nbsp;(will&nbsp;default&nbsp;to&nbsp;the&nbsp;name&nbsp;of&nbsp;`save_directory`&nbsp;in&nbsp;your<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;namespace).<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs&nbsp;(`Dict[str,&nbsp;Any]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Additional&nbsp;keyword&nbsp;arguments&nbsp;passed&nbsp;along&nbsp;to&nbsp;the&nbsp;[`~utils.PushToHubMixin.push_to_hub`]&nbsp;method.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-to_json_file"><strong>to_json_file</strong></a>(self, json_file_path: Union[str, os.PathLike])</dt><dd><tt>Save&nbsp;the&nbsp;configuration&nbsp;instance's&nbsp;parameters&nbsp;to&nbsp;a&nbsp;JSON&nbsp;file.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;json_file_path&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;the&nbsp;JSON&nbsp;file&nbsp;to&nbsp;save&nbsp;a&nbsp;configuration&nbsp;instance's&nbsp;parameters.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-to_json_string"><strong>to_json_string</strong></a>(self) -&gt; str</dt><dd><tt>Serializes&nbsp;the&nbsp;configuration&nbsp;instance&nbsp;to&nbsp;a&nbsp;JSON&nbsp;string.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`str`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;String&nbsp;containing&nbsp;all&nbsp;the&nbsp;attributes&nbsp;that&nbsp;make&nbsp;up&nbsp;the&nbsp;configuration&nbsp;instance&nbsp;in&nbsp;JSON&nbsp;format.</tt></dd></dl>

<hr>
Class methods inherited from <a href="diffusers.configuration_utils.html#ConfigMixin">diffusers.configuration_utils.ConfigMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-extract_init_dict"><strong>extract_init_dict</strong></a>(config_dict, **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-from_config"><strong>from_config</strong></a>(config: Union[diffusers.configuration_utils.FrozenDict, Dict[str, Any]] = None, return_unused_kwargs=False, **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Instantiate&nbsp;a&nbsp;Python&nbsp;class&nbsp;from&nbsp;a&nbsp;config&nbsp;dictionary.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;config&nbsp;(`Dict[str,&nbsp;Any]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;config&nbsp;dictionary&nbsp;from&nbsp;which&nbsp;the&nbsp;Python&nbsp;class&nbsp;is&nbsp;instantiated.&nbsp;Make&nbsp;sure&nbsp;to&nbsp;only&nbsp;load&nbsp;configuration<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;files&nbsp;of&nbsp;compatible&nbsp;classes.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_unused_kwargs&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;kwargs&nbsp;that&nbsp;are&nbsp;not&nbsp;consumed&nbsp;by&nbsp;the&nbsp;Python&nbsp;class&nbsp;should&nbsp;be&nbsp;returned&nbsp;or&nbsp;not.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs&nbsp;(remaining&nbsp;dictionary&nbsp;of&nbsp;keyword&nbsp;arguments,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;update&nbsp;the&nbsp;configuration&nbsp;object&nbsp;(after&nbsp;it&nbsp;is&nbsp;loaded)&nbsp;and&nbsp;initiate&nbsp;the&nbsp;Python&nbsp;class.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`**kwargs`&nbsp;are&nbsp;passed&nbsp;directly&nbsp;to&nbsp;the&nbsp;underlying&nbsp;scheduler/model's&nbsp;`__init__`&nbsp;method&nbsp;and&nbsp;eventually<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;overwrite&nbsp;the&nbsp;same&nbsp;named&nbsp;arguments&nbsp;in&nbsp;`config`.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;[`ModelMixin`]&nbsp;or&nbsp;[`SchedulerMixin`]:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;model&nbsp;or&nbsp;scheduler&nbsp;object&nbsp;instantiated&nbsp;from&nbsp;a&nbsp;config&nbsp;dictionary.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```python<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;DDPMScheduler,&nbsp;DDIMScheduler,&nbsp;PNDMScheduler<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Download&nbsp;scheduler&nbsp;from&nbsp;huggingface.co&nbsp;and&nbsp;cache.<br>
&gt;&gt;&gt;&nbsp;scheduler&nbsp;=&nbsp;DDPMScheduler.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("google/ddpm-cifar10-32")<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Instantiate&nbsp;DDIM&nbsp;scheduler&nbsp;class&nbsp;with&nbsp;same&nbsp;config&nbsp;as&nbsp;DDPM<br>
&gt;&gt;&gt;&nbsp;scheduler&nbsp;=&nbsp;DDIMScheduler.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_config">from_config</a>(scheduler.config)<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Instantiate&nbsp;PNDM&nbsp;scheduler&nbsp;class&nbsp;with&nbsp;same&nbsp;config&nbsp;as&nbsp;DDPM<br>
&gt;&gt;&gt;&nbsp;scheduler&nbsp;=&nbsp;PNDMScheduler.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_config">from_config</a>(scheduler.config)<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-get_config_dict"><strong>get_config_dict</strong></a>(*args, **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-load_config"><strong>load_config</strong></a>(pretrained_model_name_or_path: Union[str, os.PathLike], return_unused_kwargs=False, return_commit_hash=False, **kwargs) -&gt; Tuple[Dict[str, Any], Dict[str, Any]]<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Load&nbsp;a&nbsp;model&nbsp;or&nbsp;scheduler&nbsp;configuration.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name_or_path&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*model&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`google/ddpm-celebahq-256`)&nbsp;of&nbsp;a&nbsp;pretrained&nbsp;model&nbsp;hosted&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(for&nbsp;example&nbsp;`./my_model_directory`)&nbsp;containing&nbsp;model&nbsp;weights&nbsp;saved&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[`~ConfigMixin.save_config`].<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;cache_dir&nbsp;(`Union[str,&nbsp;os.PathLike]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;a&nbsp;directory&nbsp;where&nbsp;a&nbsp;downloaded&nbsp;pretrained&nbsp;model&nbsp;configuration&nbsp;is&nbsp;cached&nbsp;if&nbsp;the&nbsp;standard&nbsp;cache<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;not&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;output_loading_info(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;also&nbsp;return&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;missing&nbsp;keys,&nbsp;unexpected&nbsp;keys&nbsp;and&nbsp;error&nbsp;messages.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;subfolder&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`""`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;subfolder&nbsp;location&nbsp;of&nbsp;a&nbsp;model&nbsp;file&nbsp;within&nbsp;a&nbsp;larger&nbsp;model&nbsp;repository&nbsp;on&nbsp;the&nbsp;Hub&nbsp;or&nbsp;locally.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_unused_kwargs&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;unused&nbsp;keyword&nbsp;arguments&nbsp;of&nbsp;the&nbsp;config&nbsp;are&nbsp;returned.<br>
&nbsp;&nbsp;&nbsp;&nbsp;return_commit_hash&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;the&nbsp;`commit_hash`&nbsp;of&nbsp;the&nbsp;loaded&nbsp;configuration&nbsp;are&nbsp;returned.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`dict`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;all&nbsp;the&nbsp;parameters&nbsp;stored&nbsp;in&nbsp;a&nbsp;JSON&nbsp;configuration&nbsp;file.</tt></dd></dl>

<hr>
Readonly properties inherited from <a href="diffusers.configuration_utils.html#ConfigMixin">diffusers.configuration_utils.ConfigMixin</a>:<br>
<dl><dt><strong>config</strong></dt>
<dd><tt>Returns&nbsp;the&nbsp;config&nbsp;of&nbsp;the&nbsp;class&nbsp;as&nbsp;a&nbsp;frozen&nbsp;dictionary<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`Dict[str,&nbsp;Any]`:&nbsp;Config&nbsp;of&nbsp;the&nbsp;class.</tt></dd>
</dl>
<hr>
Data descriptors inherited from <a href="diffusers.configuration_utils.html#ConfigMixin">diffusers.configuration_utils.ConfigMixin</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="diffusers.configuration_utils.html#ConfigMixin">diffusers.configuration_utils.ConfigMixin</a>:<br>
<dl><dt><strong>has_compatibles</strong> = False</dl>

<dl><dt><strong>ignore_for_config</strong> = []</dl>

<hr>
Methods inherited from <a href="diffusers.utils.hub_utils.html#PushToHubMixin">diffusers.utils.hub_utils.PushToHubMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-push_to_hub"><strong>push_to_hub</strong></a>(self, repo_id: str, commit_message: Optional[str] = None, private: Optional[bool] = None, token: Optional[str] = None, create_pr: bool = False, safe_serialization: bool = True, variant: Optional[str] = None) -&gt; str</dt><dd><tt>Upload&nbsp;model,&nbsp;scheduler,&nbsp;or&nbsp;pipeline&nbsp;files&nbsp;to&nbsp;the&nbsp;ü§ó&nbsp;Hugging&nbsp;Face&nbsp;Hub.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;repo_id&nbsp;(`str`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;name&nbsp;of&nbsp;the&nbsp;repository&nbsp;you&nbsp;want&nbsp;to&nbsp;push&nbsp;your&nbsp;model,&nbsp;scheduler,&nbsp;or&nbsp;pipeline&nbsp;files&nbsp;to.&nbsp;It&nbsp;should<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;contain&nbsp;your&nbsp;organization&nbsp;name&nbsp;when&nbsp;pushing&nbsp;to&nbsp;an&nbsp;organization.&nbsp;`repo_id`&nbsp;can&nbsp;also&nbsp;be&nbsp;a&nbsp;path&nbsp;to&nbsp;a&nbsp;local<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;directory.<br>
&nbsp;&nbsp;&nbsp;&nbsp;commit_message&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Message&nbsp;to&nbsp;commit&nbsp;while&nbsp;pushing.&nbsp;Default&nbsp;to&nbsp;`"Upload&nbsp;{object}"`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;(`bool`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;the&nbsp;repository&nbsp;created&nbsp;should&nbsp;be&nbsp;private.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;The&nbsp;token&nbsp;generated&nbsp;when&nbsp;running<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`huggingface-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`).<br>
&nbsp;&nbsp;&nbsp;&nbsp;create_pr&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;create&nbsp;a&nbsp;PR&nbsp;with&nbsp;the&nbsp;uploaded&nbsp;files&nbsp;or&nbsp;directly&nbsp;commit.<br>
&nbsp;&nbsp;&nbsp;&nbsp;safe_serialization&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;convert&nbsp;the&nbsp;model&nbsp;weights&nbsp;to&nbsp;the&nbsp;`safetensors`&nbsp;format.<br>
&nbsp;&nbsp;&nbsp;&nbsp;variant&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;specified,&nbsp;weights&nbsp;are&nbsp;saved&nbsp;in&nbsp;the&nbsp;format&nbsp;`pytorch_model.&lt;variant&gt;.bin`.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```python<br>
from&nbsp;diffusers&nbsp;import&nbsp;UNet2DConditionModel<br>
&nbsp;<br>
unet&nbsp;=&nbsp;UNet2DConditionModel.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("stabilityai/stable-diffusion-2",&nbsp;subfolder="unet")<br>
&nbsp;<br>
#&nbsp;Push&nbsp;the&nbsp;`unet`&nbsp;to&nbsp;your&nbsp;namespace&nbsp;with&nbsp;the&nbsp;name&nbsp;"my-finetuned-unet".<br>
unet.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-push_to_hub">push_to_hub</a>("my-finetuned-unet")<br>
&nbsp;<br>
#&nbsp;Push&nbsp;the&nbsp;`unet`&nbsp;to&nbsp;an&nbsp;organization&nbsp;with&nbsp;the&nbsp;name&nbsp;"my-finetuned-unet".<br>
unet.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-push_to_hub">push_to_hub</a>("your-org/my-finetuned-unet")<br>
```</tt></dd></dl>

<hr>
Methods inherited from <a href="diffusers.pipelines.pipeline_utils.html#StableDiffusionMixin">diffusers.pipelines.pipeline_utils.StableDiffusionMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-disable_freeu"><strong>disable_freeu</strong></a>(self)</dt><dd><tt>Disables&nbsp;the&nbsp;FreeU&nbsp;mechanism&nbsp;if&nbsp;enabled.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-disable_vae_slicing"><strong>disable_vae_slicing</strong></a>(self)</dt><dd><tt>Disable&nbsp;sliced&nbsp;VAE&nbsp;decoding.&nbsp;If&nbsp;`enable_vae_slicing`&nbsp;was&nbsp;previously&nbsp;enabled,&nbsp;this&nbsp;method&nbsp;will&nbsp;go&nbsp;back&nbsp;to<br>
computing&nbsp;decoding&nbsp;in&nbsp;one&nbsp;step.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-disable_vae_tiling"><strong>disable_vae_tiling</strong></a>(self)</dt><dd><tt>Disable&nbsp;tiled&nbsp;VAE&nbsp;decoding.&nbsp;If&nbsp;`enable_vae_tiling`&nbsp;was&nbsp;previously&nbsp;enabled,&nbsp;this&nbsp;method&nbsp;will&nbsp;go&nbsp;back&nbsp;to<br>
computing&nbsp;decoding&nbsp;in&nbsp;one&nbsp;step.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_freeu"><strong>enable_freeu</strong></a>(self, s1: float, s2: float, b1: float, b2: float)</dt><dd><tt>Enables&nbsp;the&nbsp;FreeU&nbsp;mechanism&nbsp;as&nbsp;in&nbsp;<a href="https://arxiv.org/abs/2309.11497">https://arxiv.org/abs/2309.11497</a>.<br>
&nbsp;<br>
The&nbsp;suffixes&nbsp;after&nbsp;the&nbsp;scaling&nbsp;factors&nbsp;represent&nbsp;the&nbsp;stages&nbsp;where&nbsp;they&nbsp;are&nbsp;being&nbsp;applied.<br>
&nbsp;<br>
Please&nbsp;refer&nbsp;to&nbsp;the&nbsp;[official&nbsp;repository](<a href="https://github.com/ChenyangSi/FreeU">https://github.com/ChenyangSi/FreeU</a>)&nbsp;for&nbsp;combinations&nbsp;of&nbsp;the&nbsp;values<br>
that&nbsp;are&nbsp;known&nbsp;to&nbsp;work&nbsp;well&nbsp;for&nbsp;different&nbsp;pipelines&nbsp;such&nbsp;as&nbsp;Stable&nbsp;Diffusion&nbsp;v1,&nbsp;v2,&nbsp;and&nbsp;Stable&nbsp;Diffusion&nbsp;XL.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;s1&nbsp;(`float`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Scaling&nbsp;factor&nbsp;for&nbsp;stage&nbsp;1&nbsp;to&nbsp;attenuate&nbsp;the&nbsp;contributions&nbsp;of&nbsp;the&nbsp;skip&nbsp;features.&nbsp;This&nbsp;is&nbsp;done&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mitigate&nbsp;"oversmoothing&nbsp;effect"&nbsp;in&nbsp;the&nbsp;enhanced&nbsp;denoising&nbsp;process.<br>
&nbsp;&nbsp;&nbsp;&nbsp;s2&nbsp;(`float`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Scaling&nbsp;factor&nbsp;for&nbsp;stage&nbsp;2&nbsp;to&nbsp;attenuate&nbsp;the&nbsp;contributions&nbsp;of&nbsp;the&nbsp;skip&nbsp;features.&nbsp;This&nbsp;is&nbsp;done&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mitigate&nbsp;"oversmoothing&nbsp;effect"&nbsp;in&nbsp;the&nbsp;enhanced&nbsp;denoising&nbsp;process.<br>
&nbsp;&nbsp;&nbsp;&nbsp;b1&nbsp;(`float`):&nbsp;Scaling&nbsp;factor&nbsp;for&nbsp;stage&nbsp;1&nbsp;to&nbsp;amplify&nbsp;the&nbsp;contributions&nbsp;of&nbsp;backbone&nbsp;features.<br>
&nbsp;&nbsp;&nbsp;&nbsp;b2&nbsp;(`float`):&nbsp;Scaling&nbsp;factor&nbsp;for&nbsp;stage&nbsp;2&nbsp;to&nbsp;amplify&nbsp;the&nbsp;contributions&nbsp;of&nbsp;backbone&nbsp;features.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_vae_slicing"><strong>enable_vae_slicing</strong></a>(self)</dt><dd><tt>Enable&nbsp;sliced&nbsp;VAE&nbsp;decoding.&nbsp;When&nbsp;this&nbsp;option&nbsp;is&nbsp;enabled,&nbsp;the&nbsp;VAE&nbsp;will&nbsp;split&nbsp;the&nbsp;input&nbsp;tensor&nbsp;in&nbsp;slices&nbsp;to<br>
compute&nbsp;decoding&nbsp;in&nbsp;several&nbsp;steps.&nbsp;This&nbsp;is&nbsp;useful&nbsp;to&nbsp;save&nbsp;some&nbsp;memory&nbsp;and&nbsp;allow&nbsp;larger&nbsp;batch&nbsp;sizes.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_vae_tiling"><strong>enable_vae_tiling</strong></a>(self)</dt><dd><tt>Enable&nbsp;tiled&nbsp;VAE&nbsp;decoding.&nbsp;When&nbsp;this&nbsp;option&nbsp;is&nbsp;enabled,&nbsp;the&nbsp;VAE&nbsp;will&nbsp;split&nbsp;the&nbsp;input&nbsp;tensor&nbsp;into&nbsp;tiles&nbsp;to<br>
compute&nbsp;decoding&nbsp;and&nbsp;encoding&nbsp;in&nbsp;several&nbsp;steps.&nbsp;This&nbsp;is&nbsp;useful&nbsp;for&nbsp;saving&nbsp;a&nbsp;large&nbsp;amount&nbsp;of&nbsp;memory&nbsp;and&nbsp;to&nbsp;allow<br>
processing&nbsp;larger&nbsp;images.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-fuse_qkv_projections"><strong>fuse_qkv_projections</strong></a>(self, unet: bool = True, vae: bool = True)</dt><dd><tt>Enables&nbsp;fused&nbsp;QKV&nbsp;projections.&nbsp;For&nbsp;self-attention&nbsp;modules,&nbsp;all&nbsp;projection&nbsp;matrices&nbsp;(i.e.,&nbsp;query,&nbsp;key,&nbsp;value)<br>
are&nbsp;fused.&nbsp;For&nbsp;cross-attention&nbsp;modules,&nbsp;key&nbsp;and&nbsp;value&nbsp;projection&nbsp;matrices&nbsp;are&nbsp;fused.<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
This&nbsp;API&nbsp;is&nbsp;üß™&nbsp;experimental.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;unet&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`True`):&nbsp;To&nbsp;apply&nbsp;fusion&nbsp;on&nbsp;the&nbsp;UNet.<br>
&nbsp;&nbsp;&nbsp;&nbsp;vae&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`True`):&nbsp;To&nbsp;apply&nbsp;fusion&nbsp;on&nbsp;the&nbsp;VAE.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-unfuse_qkv_projections"><strong>unfuse_qkv_projections</strong></a>(self, unet: bool = True, vae: bool = True)</dt><dd><tt>Disable&nbsp;QKV&nbsp;projection&nbsp;fusion&nbsp;if&nbsp;enabled.<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
This&nbsp;API&nbsp;is&nbsp;üß™&nbsp;experimental.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;unet&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`True`):&nbsp;To&nbsp;apply&nbsp;fusion&nbsp;on&nbsp;the&nbsp;UNet.<br>
&nbsp;&nbsp;&nbsp;&nbsp;vae&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`True`):&nbsp;To&nbsp;apply&nbsp;fusion&nbsp;on&nbsp;the&nbsp;VAE.</tt></dd></dl>

<hr>
Methods inherited from <a href="diffusers.loaders.textual_inversion.html#TextualInversionLoaderMixin">diffusers.loaders.textual_inversion.TextualInversionLoaderMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion"><strong>load_textual_inversion</strong></a>(self, pretrained_model_name_or_path: Union[str, List[str], Dict[str, torch.Tensor], List[Dict[str, torch.Tensor]]], token: Union[str, List[str], NoneType] = None, tokenizer: Optional[ForwardRef('PreTrainedTokenizer')] = None, text_encoder: Optional[ForwardRef('PreTrainedModel')] = None, **kwargs)</dt><dd><tt>Load&nbsp;Textual&nbsp;Inversion&nbsp;embeddings&nbsp;into&nbsp;the&nbsp;text&nbsp;encoder&nbsp;of&nbsp;[`StableDiffusionPipeline`]&nbsp;(both&nbsp;ü§ó&nbsp;Diffusers&nbsp;and<br>
Automatic1111&nbsp;formats&nbsp;are&nbsp;supported).<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name_or_path&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`&nbsp;or&nbsp;`List[str&nbsp;or&nbsp;os.PathLike]`&nbsp;or&nbsp;`Dict`&nbsp;or&nbsp;`List[Dict]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either&nbsp;one&nbsp;of&nbsp;the&nbsp;following&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;them:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*model&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`sd-concepts-library/low-poly-hd-logos-icons`)&nbsp;of&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pretrained&nbsp;model&nbsp;hosted&nbsp;on&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(for&nbsp;example&nbsp;`./my_text_inversion_directory/`)&nbsp;containing&nbsp;the&nbsp;textual<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inversion&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*file*&nbsp;(for&nbsp;example&nbsp;`./my_text_inversions.pt`)&nbsp;containing&nbsp;textual&nbsp;inversion&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;[torch&nbsp;state<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dict](<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict">https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict</a>).<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Override&nbsp;the&nbsp;token&nbsp;to&nbsp;use&nbsp;for&nbsp;the&nbsp;textual&nbsp;inversion&nbsp;weights.&nbsp;If&nbsp;`pretrained_model_name_or_path`&nbsp;is&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list,&nbsp;then&nbsp;`token`&nbsp;must&nbsp;also&nbsp;be&nbsp;a&nbsp;list&nbsp;of&nbsp;equal&nbsp;length.<br>
&nbsp;&nbsp;&nbsp;&nbsp;text_encoder&nbsp;([`~transformers.CLIPTextModel`],&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Frozen&nbsp;text-encoder&nbsp;([clip-vit-large-patch14](<a href="https://huggingface.co/openai/clip-vit-large-patch14">https://huggingface.co/openai/clip-vit-large-patch14</a>)).<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;not&nbsp;specified,&nbsp;function&nbsp;will&nbsp;take&nbsp;self.<strong>tokenizer</strong>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tokenizer&nbsp;([`~transformers.CLIPTokenizer`],&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;`CLIPTokenizer`&nbsp;to&nbsp;tokenize&nbsp;text.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;function&nbsp;will&nbsp;take&nbsp;self.<strong>tokenizer</strong>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_name&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Name&nbsp;of&nbsp;a&nbsp;custom&nbsp;weight&nbsp;file.&nbsp;This&nbsp;should&nbsp;be&nbsp;used&nbsp;when:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;The&nbsp;saved&nbsp;textual&nbsp;inversion&nbsp;file&nbsp;is&nbsp;in&nbsp;ü§ó&nbsp;Diffusers&nbsp;format,&nbsp;but&nbsp;was&nbsp;saved&nbsp;under&nbsp;a&nbsp;specific&nbsp;weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;such&nbsp;as&nbsp;`text_inv.bin`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;The&nbsp;saved&nbsp;textual&nbsp;inversion&nbsp;file&nbsp;is&nbsp;in&nbsp;the&nbsp;Automatic1111&nbsp;format.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cache_dir&nbsp;(`Union[str,&nbsp;os.PathLike]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;a&nbsp;directory&nbsp;where&nbsp;a&nbsp;downloaded&nbsp;pretrained&nbsp;model&nbsp;configuration&nbsp;is&nbsp;cached&nbsp;if&nbsp;the&nbsp;standard&nbsp;cache<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;not&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;subfolder&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`""`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;subfolder&nbsp;location&nbsp;of&nbsp;a&nbsp;model&nbsp;file&nbsp;within&nbsp;a&nbsp;larger&nbsp;model&nbsp;repository&nbsp;on&nbsp;the&nbsp;Hub&nbsp;or&nbsp;locally.<br>
&nbsp;&nbsp;&nbsp;&nbsp;mirror&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mirror&nbsp;source&nbsp;to&nbsp;resolve&nbsp;accessibility&nbsp;issues&nbsp;if&nbsp;you're&nbsp;downloading&nbsp;a&nbsp;model&nbsp;in&nbsp;China.&nbsp;We&nbsp;do&nbsp;not<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;guarantee&nbsp;the&nbsp;timeliness&nbsp;or&nbsp;safety&nbsp;of&nbsp;the&nbsp;source,&nbsp;and&nbsp;you&nbsp;should&nbsp;refer&nbsp;to&nbsp;the&nbsp;mirror&nbsp;site&nbsp;for&nbsp;more<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;information.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
To&nbsp;load&nbsp;a&nbsp;Textual&nbsp;Inversion&nbsp;embedding&nbsp;vector&nbsp;in&nbsp;ü§ó&nbsp;Diffusers&nbsp;format:<br>
&nbsp;<br>
```py<br>
from&nbsp;diffusers&nbsp;import&nbsp;StableDiffusionPipeline<br>
import&nbsp;torch<br>
&nbsp;<br>
model_id&nbsp;=&nbsp;"runwayml/stable-diffusion-v1-5"<br>
pipe&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>(model_id,&nbsp;torch_dtype=torch.float16).<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>("cuda")<br>
&nbsp;<br>
pipe.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>("sd-concepts-library/cat-toy")<br>
&nbsp;<br>
prompt&nbsp;=&nbsp;"A&nbsp;&lt;cat-toy&gt;&nbsp;backpack"<br>
&nbsp;<br>
image&nbsp;=&nbsp;pipe(prompt,&nbsp;num_inference_steps=50).images[0]<br>
image.save("cat-backpack.png")<br>
```<br>
&nbsp;<br>
To&nbsp;load&nbsp;a&nbsp;Textual&nbsp;Inversion&nbsp;embedding&nbsp;vector&nbsp;in&nbsp;Automatic1111&nbsp;format,&nbsp;make&nbsp;sure&nbsp;to&nbsp;download&nbsp;the&nbsp;vector&nbsp;first<br>
(for&nbsp;example&nbsp;from&nbsp;[civitAI](<a href="https://civitai.com/models/3036?modelVersionId=9857">https://civitai.com/models/3036?modelVersionId=9857</a>))&nbsp;and&nbsp;then&nbsp;load&nbsp;the&nbsp;vector<br>
locally:<br>
&nbsp;<br>
```py<br>
from&nbsp;diffusers&nbsp;import&nbsp;StableDiffusionPipeline<br>
import&nbsp;torch<br>
&nbsp;<br>
model_id&nbsp;=&nbsp;"runwayml/stable-diffusion-v1-5"<br>
pipe&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>(model_id,&nbsp;torch_dtype=torch.float16).<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>("cuda")<br>
&nbsp;<br>
pipe.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>("./charturnerv2.pt",&nbsp;token="charturnerv2")<br>
&nbsp;<br>
prompt&nbsp;=&nbsp;"charturnerv2,&nbsp;multiple&nbsp;views&nbsp;of&nbsp;the&nbsp;same&nbsp;character&nbsp;in&nbsp;the&nbsp;same&nbsp;outfit,&nbsp;a&nbsp;character&nbsp;turnaround&nbsp;of&nbsp;a&nbsp;woman&nbsp;wearing&nbsp;a&nbsp;black&nbsp;jacket&nbsp;and&nbsp;red&nbsp;shirt,&nbsp;best&nbsp;quality,&nbsp;intricate&nbsp;details."<br>
&nbsp;<br>
image&nbsp;=&nbsp;pipe(prompt,&nbsp;num_inference_steps=50).images[0]<br>
image.save("character.png")<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-maybe_convert_prompt"><strong>maybe_convert_prompt</strong></a>(self, prompt: Union[str, List[str]], tokenizer: 'PreTrainedTokenizer')</dt><dd><tt>Processes&nbsp;prompts&nbsp;that&nbsp;include&nbsp;a&nbsp;special&nbsp;token&nbsp;corresponding&nbsp;to&nbsp;a&nbsp;multi-vector&nbsp;textual&nbsp;inversion&nbsp;embedding&nbsp;to<br>
be&nbsp;replaced&nbsp;with&nbsp;multiple&nbsp;special&nbsp;tokens&nbsp;each&nbsp;corresponding&nbsp;to&nbsp;one&nbsp;of&nbsp;the&nbsp;vectors.&nbsp;If&nbsp;the&nbsp;prompt&nbsp;has&nbsp;no&nbsp;textual<br>
inversion&nbsp;token&nbsp;or&nbsp;if&nbsp;the&nbsp;textual&nbsp;inversion&nbsp;token&nbsp;is&nbsp;a&nbsp;single&nbsp;vector,&nbsp;the&nbsp;input&nbsp;prompt&nbsp;is&nbsp;returned.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt&nbsp;(`str`&nbsp;or&nbsp;list&nbsp;of&nbsp;`str`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;prompt&nbsp;or&nbsp;prompts&nbsp;to&nbsp;guide&nbsp;the&nbsp;image&nbsp;generation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;tokenizer&nbsp;(`PreTrainedTokenizer`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;tokenizer&nbsp;responsible&nbsp;for&nbsp;encoding&nbsp;the&nbsp;prompt&nbsp;into&nbsp;input&nbsp;tokens.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;`str`&nbsp;or&nbsp;list&nbsp;of&nbsp;`str`:&nbsp;The&nbsp;converted&nbsp;prompt</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-unload_textual_inversion"><strong>unload_textual_inversion</strong></a>(self, tokens: Union[str, List[str], NoneType] = None, tokenizer: Optional[ForwardRef('PreTrainedTokenizer')] = None, text_encoder: Optional[ForwardRef('PreTrainedModel')] = None)</dt><dd><tt>Unload&nbsp;Textual&nbsp;Inversion&nbsp;embeddings&nbsp;from&nbsp;the&nbsp;text&nbsp;encoder&nbsp;of&nbsp;[`StableDiffusionPipeline`]<br>
&nbsp;<br>
Example:<br>
```py<br>
from&nbsp;diffusers&nbsp;import&nbsp;AutoPipelineForText2Image<br>
import&nbsp;torch<br>
&nbsp;<br>
pipeline&nbsp;=&nbsp;AutoPipelineForText2Image.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("runwayml/stable-diffusion-v1-5")<br>
&nbsp;<br>
#&nbsp;Example&nbsp;1<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>("sd-concepts-library/gta5-artwork")<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>("sd-concepts-library/moeb-style")<br>
&nbsp;<br>
#&nbsp;Remove&nbsp;all&nbsp;token&nbsp;embeddings<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-unload_textual_inversion">unload_textual_inversion</a>()<br>
&nbsp;<br>
#&nbsp;Example&nbsp;2<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>("sd-concepts-library/moeb-style")<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>("sd-concepts-library/gta5-artwork")<br>
&nbsp;<br>
#&nbsp;Remove&nbsp;just&nbsp;one&nbsp;token<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-unload_textual_inversion">unload_textual_inversion</a>("&lt;moe-bius&gt;")<br>
&nbsp;<br>
#&nbsp;Example&nbsp;3:&nbsp;unload&nbsp;from&nbsp;SDXL<br>
pipeline&nbsp;=&nbsp;AutoPipelineForText2Image.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>("stabilityai/stable-diffusion-xl-base-1.0")<br>
embedding_path&nbsp;=&nbsp;hf_hub_download(<br>
&nbsp;&nbsp;&nbsp;&nbsp;repo_id="linoyts/web_y2k",&nbsp;filename="web_y2k_emb.safetensors",&nbsp;repo_type="model"<br>
)<br>
&nbsp;<br>
#&nbsp;load&nbsp;embeddings&nbsp;to&nbsp;the&nbsp;text&nbsp;encoders<br>
state_dict&nbsp;=&nbsp;load_file(embedding_path)<br>
&nbsp;<br>
#&nbsp;load&nbsp;embeddings&nbsp;of&nbsp;text_encoder&nbsp;1&nbsp;(CLIP&nbsp;ViT-L/14)<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict["clip_l"],<br>
&nbsp;&nbsp;&nbsp;&nbsp;token=["&lt;s0&gt;",&nbsp;"&lt;s1&gt;"],<br>
&nbsp;&nbsp;&nbsp;&nbsp;text_encoder=pipeline.text_encoder,<br>
&nbsp;&nbsp;&nbsp;&nbsp;tokenizer=pipeline.tokenizer,<br>
)<br>
#&nbsp;load&nbsp;embeddings&nbsp;of&nbsp;text_encoder&nbsp;2&nbsp;(CLIP&nbsp;ViT-G/14)<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_textual_inversion">load_textual_inversion</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict["clip_g"],<br>
&nbsp;&nbsp;&nbsp;&nbsp;token=["&lt;s0&gt;",&nbsp;"&lt;s1&gt;"],<br>
&nbsp;&nbsp;&nbsp;&nbsp;text_encoder=pipeline.text_encoder_2,<br>
&nbsp;&nbsp;&nbsp;&nbsp;tokenizer=pipeline.tokenizer_2,<br>
)<br>
&nbsp;<br>
#&nbsp;Unload&nbsp;explicitly&nbsp;from&nbsp;both&nbsp;text&nbsp;encoders&nbsp;abd&nbsp;tokenizers<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-unload_textual_inversion">unload_textual_inversion</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;tokens=["&lt;s0&gt;",&nbsp;"&lt;s1&gt;"],&nbsp;text_encoder=pipeline.text_encoder,&nbsp;tokenizer=pipeline.tokenizer<br>
)<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-unload_textual_inversion">unload_textual_inversion</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;tokens=["&lt;s0&gt;",&nbsp;"&lt;s1&gt;"],&nbsp;text_encoder=pipeline.text_encoder_2,&nbsp;tokenizer=pipeline.tokenizer_2<br>
)<br>
```</tt></dd></dl>

<hr>
Class methods inherited from <a href="diffusers.loaders.single_file.html#FromSingleFileMixin">diffusers.loaders.single_file.FromSingleFileMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-from_single_file"><strong>from_single_file</strong></a>(pretrained_model_link_or_path, **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Instantiate&nbsp;a&nbsp;[`DiffusionPipeline`]&nbsp;from&nbsp;pretrained&nbsp;pipeline&nbsp;weights&nbsp;saved&nbsp;in&nbsp;the&nbsp;`.ckpt`&nbsp;or&nbsp;`.safetensors`<br>
format.&nbsp;The&nbsp;pipeline&nbsp;is&nbsp;set&nbsp;in&nbsp;evaluation&nbsp;mode&nbsp;(`model.eval()`)&nbsp;by&nbsp;default.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_link_or_path&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;link&nbsp;to&nbsp;the&nbsp;`.ckpt`&nbsp;file&nbsp;(for&nbsp;example<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`"<a href="https://huggingface.co/&lt;repo_id&gt;/blob/main/&lt;path_to_file&gt;.ckpt">https://huggingface.co/&lt;repo_id&gt;/blob/main/&lt;path_to_file&gt;.ckpt</a>"`)&nbsp;on&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*file*&nbsp;containing&nbsp;all&nbsp;pipeline&nbsp;weights.<br>
&nbsp;&nbsp;&nbsp;&nbsp;torch_dtype&nbsp;(`str`&nbsp;or&nbsp;`torch.dtype`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Override&nbsp;the&nbsp;default&nbsp;`torch.dtype`&nbsp;and&nbsp;load&nbsp;the&nbsp;model&nbsp;with&nbsp;another&nbsp;dtype.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cache_dir&nbsp;(`Union[str,&nbsp;os.PathLike]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;a&nbsp;directory&nbsp;where&nbsp;a&nbsp;downloaded&nbsp;pretrained&nbsp;model&nbsp;configuration&nbsp;is&nbsp;cached&nbsp;if&nbsp;the&nbsp;standard&nbsp;cache<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;not&nbsp;used.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;original_config_file&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;path&nbsp;to&nbsp;the&nbsp;original&nbsp;config&nbsp;file&nbsp;that&nbsp;was&nbsp;used&nbsp;to&nbsp;train&nbsp;the&nbsp;model.&nbsp;If&nbsp;not&nbsp;provided,&nbsp;the&nbsp;config&nbsp;file<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;will&nbsp;be&nbsp;inferred&nbsp;from&nbsp;the&nbsp;checkpoint&nbsp;file.<br>
&nbsp;&nbsp;&nbsp;&nbsp;config&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*repo&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`CompVis/ldm-text2im-large-256`)&nbsp;of&nbsp;a&nbsp;pretrained&nbsp;pipeline<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hosted&nbsp;on&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(for&nbsp;example&nbsp;`./my_pipeline_directory/`)&nbsp;containing&nbsp;the&nbsp;pipeline<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;component&nbsp;configs&nbsp;in&nbsp;Diffusers&nbsp;format.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs&nbsp;(remaining&nbsp;dictionary&nbsp;of&nbsp;keyword&nbsp;arguments,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;used&nbsp;to&nbsp;overwrite&nbsp;load&nbsp;and&nbsp;saveable&nbsp;variables&nbsp;(the&nbsp;pipeline&nbsp;components&nbsp;of&nbsp;the&nbsp;specific&nbsp;pipeline<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class).&nbsp;The&nbsp;overwritten&nbsp;components&nbsp;are&nbsp;passed&nbsp;directly&nbsp;to&nbsp;the&nbsp;pipelines&nbsp;`__init__`&nbsp;method.&nbsp;See&nbsp;example<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;below&nbsp;for&nbsp;more&nbsp;information.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```py<br>
&gt;&gt;&gt;&nbsp;from&nbsp;diffusers&nbsp;import&nbsp;StableDiffusionPipeline<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Download&nbsp;pipeline&nbsp;from&nbsp;huggingface.co&nbsp;and&nbsp;cache.<br>
&gt;&gt;&gt;&nbsp;pipeline&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_single_file">from_single_file</a>(<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"<a href="https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors">https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors</a>"<br>
...&nbsp;)<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Download&nbsp;pipeline&nbsp;from&nbsp;local&nbsp;file<br>
&gt;&gt;&gt;&nbsp;#&nbsp;file&nbsp;is&nbsp;downloaded&nbsp;under&nbsp;./v1-5-pruned-emaonly.ckpt<br>
&gt;&gt;&gt;&nbsp;pipeline&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_single_file">from_single_file</a>("./v1-5-pruned-emaonly.ckpt")<br>
&nbsp;<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Enable&nbsp;float16&nbsp;and&nbsp;move&nbsp;to&nbsp;GPU<br>
&gt;&gt;&gt;&nbsp;pipeline&nbsp;=&nbsp;StableDiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_single_file">from_single_file</a>(<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"<a href="https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.ckpt">https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.ckpt</a>",<br>
...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;torch_dtype=torch.float16,<br>
...&nbsp;)<br>
&gt;&gt;&gt;&nbsp;pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>("cuda")<br>
```</tt></dd></dl>

<hr>
Methods inherited from <a href="diffusers.loaders.lora_pipeline.html#StableDiffusionXLLoraLoaderMixin">diffusers.loaders.lora_pipeline.StableDiffusionXLLoraLoaderMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-fuse_lora"><strong>fuse_lora</strong></a>(self, components: List[str] = ['unet', 'text_encoder', 'text_encoder_2'], lora_scale: float = 1.0, safe_fusing: bool = False, adapter_names: Optional[List[str]] = None, **kwargs)</dt><dd><tt>Fuses&nbsp;the&nbsp;LoRA&nbsp;parameters&nbsp;into&nbsp;the&nbsp;original&nbsp;parameters&nbsp;of&nbsp;the&nbsp;corresponding&nbsp;blocks.<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
This&nbsp;is&nbsp;an&nbsp;experimental&nbsp;API.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;components:&nbsp;(`List[str]`):&nbsp;List&nbsp;of&nbsp;LoRA-injectable&nbsp;components&nbsp;to&nbsp;fuse&nbsp;the&nbsp;LoRAs&nbsp;into.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lora_scale&nbsp;(`float`,&nbsp;defaults&nbsp;to&nbsp;1.0):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Controls&nbsp;how&nbsp;much&nbsp;to&nbsp;influence&nbsp;the&nbsp;outputs&nbsp;with&nbsp;the&nbsp;LoRA&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;safe_fusing&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;check&nbsp;fused&nbsp;weights&nbsp;for&nbsp;NaN&nbsp;values&nbsp;before&nbsp;fusing&nbsp;and&nbsp;if&nbsp;values&nbsp;are&nbsp;NaN&nbsp;not&nbsp;fusing&nbsp;them.<br>
&nbsp;&nbsp;&nbsp;&nbsp;adapter_names&nbsp;(`List[str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adapter&nbsp;names&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;fusing.&nbsp;If&nbsp;nothing&nbsp;is&nbsp;passed,&nbsp;all&nbsp;active&nbsp;adapters&nbsp;will&nbsp;be&nbsp;fused.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
```py<br>
from&nbsp;diffusers&nbsp;import&nbsp;DiffusionPipeline<br>
import&nbsp;torch<br>
&nbsp;<br>
pipeline&nbsp;=&nbsp;DiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;"stabilityai/stable-diffusion-xl-base-1.0",&nbsp;torch_dtype=torch.float16<br>
).<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>("cuda")<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_lora_weights">load_lora_weights</a>("nerijs/pixel-art-xl",&nbsp;weight_name="pixel-art-xl.safetensors",&nbsp;adapter_name="pixel")<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-fuse_lora">fuse_lora</a>(lora_scale=0.7)<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-load_lora_weights"><strong>load_lora_weights</strong></a>(self, pretrained_model_name_or_path_or_dict: Union[str, Dict[str, torch.Tensor]], adapter_name: Optional[str] = None, **kwargs)</dt><dd><tt>Load&nbsp;LoRA&nbsp;weights&nbsp;specified&nbsp;in&nbsp;`pretrained_model_name_or_path_or_dict`&nbsp;into&nbsp;`self.<strong>unet</strong>`&nbsp;and<br>
`self.<strong>text_encoder</strong>`.<br>
&nbsp;<br>
All&nbsp;kwargs&nbsp;are&nbsp;forwarded&nbsp;to&nbsp;`self.<strong>lora_state_dict</strong>`.<br>
&nbsp;<br>
See&nbsp;[`~loaders.StableDiffusionLoraLoaderMixin.lora_state_dict`]&nbsp;for&nbsp;more&nbsp;details&nbsp;on&nbsp;how&nbsp;the&nbsp;state&nbsp;dict&nbsp;is<br>
loaded.<br>
&nbsp;<br>
See&nbsp;[`~loaders.StableDiffusionLoraLoaderMixin.load_lora_into_unet`]&nbsp;for&nbsp;more&nbsp;details&nbsp;on&nbsp;how&nbsp;the&nbsp;state&nbsp;dict&nbsp;is<br>
loaded&nbsp;into&nbsp;`self.<strong>unet</strong>`.<br>
&nbsp;<br>
See&nbsp;[`~loaders.StableDiffusionLoraLoaderMixin.load_lora_into_text_encoder`]&nbsp;for&nbsp;more&nbsp;details&nbsp;on&nbsp;how&nbsp;the&nbsp;state<br>
dict&nbsp;is&nbsp;loaded&nbsp;into&nbsp;`self.<strong>text_encoder</strong>`.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name_or_path_or_dict&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`&nbsp;or&nbsp;`dict`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See&nbsp;[`~loaders.StableDiffusionLoraLoaderMixin.lora_state_dict`].<br>
&nbsp;&nbsp;&nbsp;&nbsp;adapter_name&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adapter&nbsp;name&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;referencing&nbsp;the&nbsp;loaded&nbsp;adapter&nbsp;model.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`default_{i}`&nbsp;where&nbsp;i&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;adapters&nbsp;being&nbsp;loaded.<br>
&nbsp;&nbsp;&nbsp;&nbsp;kwargs&nbsp;(`dict`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See&nbsp;[`~loaders.StableDiffusionLoraLoaderMixin.lora_state_dict`].</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-unfuse_lora"><strong>unfuse_lora</strong></a>(self, components: List[str] = ['unet', 'text_encoder', 'text_encoder_2'], **kwargs)</dt><dd><tt>Reverses&nbsp;the&nbsp;effect&nbsp;of<br>
[`pipe.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-fuse_lora">fuse_lora</a>()`](<a href="https://huggingface.co/docs/diffusers/main/en/api/loaders#diffusers.loaders.LoraBaseMixin.fuse_lora">https://huggingface.co/docs/diffusers/main/en/api/loaders#diffusers.loaders.LoraBaseMixin.fuse_lora</a>).<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
This&nbsp;is&nbsp;an&nbsp;experimental&nbsp;API.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;components&nbsp;(`List[str]`):&nbsp;List&nbsp;of&nbsp;LoRA-injectable&nbsp;components&nbsp;to&nbsp;unfuse&nbsp;LoRA&nbsp;from.<br>
&nbsp;&nbsp;&nbsp;&nbsp;unfuse_unet&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`True`):&nbsp;Whether&nbsp;to&nbsp;unfuse&nbsp;the&nbsp;UNet&nbsp;LoRA&nbsp;parameters.<br>
&nbsp;&nbsp;&nbsp;&nbsp;unfuse_text_encoder&nbsp;(`bool`,&nbsp;defaults&nbsp;to&nbsp;`True`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;unfuse&nbsp;the&nbsp;text&nbsp;encoder&nbsp;LoRA&nbsp;parameters.&nbsp;If&nbsp;the&nbsp;text&nbsp;encoder&nbsp;wasn't&nbsp;monkey-patched&nbsp;with&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LoRA&nbsp;parameters&nbsp;then&nbsp;it&nbsp;won't&nbsp;have&nbsp;any&nbsp;effect.</tt></dd></dl>

<hr>
Class methods inherited from <a href="diffusers.loaders.lora_pipeline.html#StableDiffusionXLLoraLoaderMixin">diffusers.loaders.lora_pipeline.StableDiffusionXLLoraLoaderMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-load_lora_into_text_encoder"><strong>load_lora_into_text_encoder</strong></a>(state_dict, network_alphas, text_encoder, prefix=None, lora_scale=1.0, adapter_name=None, _pipeline=None)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>This&nbsp;will&nbsp;load&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;specified&nbsp;in&nbsp;`state_dict`&nbsp;into&nbsp;`text_encoder`<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(`dict`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;standard&nbsp;state&nbsp;dict&nbsp;containing&nbsp;the&nbsp;lora&nbsp;layer&nbsp;parameters.&nbsp;The&nbsp;key&nbsp;should&nbsp;be&nbsp;prefixed&nbsp;with&nbsp;an<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;additional&nbsp;`text_encoder`&nbsp;to&nbsp;distinguish&nbsp;between&nbsp;unet&nbsp;lora&nbsp;layers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;network_alphas&nbsp;(`Dict[str,&nbsp;float]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See&nbsp;`LoRALinearLayer`&nbsp;for&nbsp;more&nbsp;details.<br>
&nbsp;&nbsp;&nbsp;&nbsp;text_encoder&nbsp;(`CLIPTextModel`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;text&nbsp;encoder&nbsp;model&nbsp;to&nbsp;load&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;into.<br>
&nbsp;&nbsp;&nbsp;&nbsp;prefix&nbsp;(`str`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Expected&nbsp;prefix&nbsp;of&nbsp;the&nbsp;`text_encoder`&nbsp;in&nbsp;the&nbsp;`state_dict`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lora_scale&nbsp;(`float`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;How&nbsp;much&nbsp;to&nbsp;scale&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;lora&nbsp;linear&nbsp;layer&nbsp;before&nbsp;it&nbsp;is&nbsp;added&nbsp;with&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;regular<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lora&nbsp;layer.<br>
&nbsp;&nbsp;&nbsp;&nbsp;adapter_name&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adapter&nbsp;name&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;referencing&nbsp;the&nbsp;loaded&nbsp;adapter&nbsp;model.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`default_{i}`&nbsp;where&nbsp;i&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;adapters&nbsp;being&nbsp;loaded.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-load_lora_into_unet"><strong>load_lora_into_unet</strong></a>(state_dict, network_alphas, unet, adapter_name=None, _pipeline=None)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>This&nbsp;will&nbsp;load&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;specified&nbsp;in&nbsp;`state_dict`&nbsp;into&nbsp;`unet`.<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(`dict`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;standard&nbsp;state&nbsp;dict&nbsp;containing&nbsp;the&nbsp;lora&nbsp;layer&nbsp;parameters.&nbsp;The&nbsp;keys&nbsp;can&nbsp;either&nbsp;be&nbsp;indexed&nbsp;directly<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;into&nbsp;the&nbsp;unet&nbsp;or&nbsp;prefixed&nbsp;with&nbsp;an&nbsp;additional&nbsp;`unet`&nbsp;which&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;distinguish&nbsp;between&nbsp;text<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;encoder&nbsp;lora&nbsp;layers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;network_alphas&nbsp;(`Dict[str,&nbsp;float]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;value&nbsp;of&nbsp;the&nbsp;network&nbsp;alpha&nbsp;used&nbsp;for&nbsp;stable&nbsp;learning&nbsp;and&nbsp;preventing&nbsp;underflow.&nbsp;This&nbsp;value&nbsp;has&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;same&nbsp;meaning&nbsp;as&nbsp;the&nbsp;`--network_alpha`&nbsp;option&nbsp;in&nbsp;the&nbsp;kohya-ss&nbsp;trainer&nbsp;script.&nbsp;Refer&nbsp;to&nbsp;[this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;link](<a href="https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_network_README-en.md#execute-learning">https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_network_README-en.md#execute-learning</a>).<br>
&nbsp;&nbsp;&nbsp;&nbsp;unet&nbsp;(`UNet2DConditionModel`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;UNet&nbsp;model&nbsp;to&nbsp;load&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;into.<br>
&nbsp;&nbsp;&nbsp;&nbsp;adapter_name&nbsp;(`str`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adapter&nbsp;name&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;referencing&nbsp;the&nbsp;loaded&nbsp;adapter&nbsp;model.&nbsp;If&nbsp;not&nbsp;specified,&nbsp;it&nbsp;will&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`default_{i}`&nbsp;where&nbsp;i&nbsp;is&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;adapters&nbsp;being&nbsp;loaded.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-lora_state_dict"><strong>lora_state_dict</strong></a>(pretrained_model_name_or_path_or_dict: Union[str, Dict[str, torch.Tensor]], **kwargs)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Return&nbsp;state&nbsp;dict&nbsp;for&nbsp;lora&nbsp;weights&nbsp;and&nbsp;the&nbsp;network&nbsp;alphas.<br>
&nbsp;<br>
&lt;Tip&nbsp;warning={true}&gt;<br>
&nbsp;<br>
We&nbsp;support&nbsp;loading&nbsp;A1111&nbsp;formatted&nbsp;LoRA&nbsp;checkpoints&nbsp;in&nbsp;a&nbsp;limited&nbsp;capacity.<br>
&nbsp;<br>
This&nbsp;function&nbsp;is&nbsp;experimental&nbsp;and&nbsp;might&nbsp;change&nbsp;in&nbsp;the&nbsp;future.<br>
&nbsp;<br>
&lt;/Tip&gt;<br>
&nbsp;<br>
Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name_or_path_or_dict&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`&nbsp;or&nbsp;`dict`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*model&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`google/ddpm-celebahq-256`)&nbsp;of&nbsp;a&nbsp;pretrained&nbsp;model&nbsp;hosted&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(for&nbsp;example&nbsp;`./my_model_directory`)&nbsp;containing&nbsp;the&nbsp;model&nbsp;weights&nbsp;saved<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;[`ModelMixin.save_pretrained`].<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;[torch&nbsp;state<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dict](<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict">https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict</a>).<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;cache_dir&nbsp;(`Union[str,&nbsp;os.PathLike]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;a&nbsp;directory&nbsp;where&nbsp;a&nbsp;downloaded&nbsp;pretrained&nbsp;model&nbsp;configuration&nbsp;is&nbsp;cached&nbsp;if&nbsp;the&nbsp;standard&nbsp;cache<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;not&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;subfolder&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`""`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;subfolder&nbsp;location&nbsp;of&nbsp;a&nbsp;model&nbsp;file&nbsp;within&nbsp;a&nbsp;larger&nbsp;model&nbsp;repository&nbsp;on&nbsp;the&nbsp;Hub&nbsp;or&nbsp;locally.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_name&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;None):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Name&nbsp;of&nbsp;the&nbsp;serialized&nbsp;state&nbsp;dict&nbsp;file.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-save_lora_weights"><strong>save_lora_weights</strong></a>(save_directory: Union[str, os.PathLike], unet_lora_layers: Dict[str, Union[torch.nn.modules.module.Module, torch.Tensor]] = None, text_encoder_lora_layers: Dict[str, Union[torch.nn.modules.module.Module, torch.Tensor]] = None, text_encoder_2_lora_layers: Dict[str, Union[torch.nn.modules.module.Module, torch.Tensor]] = None, is_main_process: bool = True, weight_name: str = None, save_function: Callable = None, safe_serialization: bool = True)<font color="#909090"><font face="helvetica, arial"> from <a href="builtins.html#type">builtins.type</a></font></font></dt><dd><tt>Save&nbsp;the&nbsp;LoRA&nbsp;parameters&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;UNet&nbsp;and&nbsp;text&nbsp;encoder.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_directory&nbsp;(`str`&nbsp;or&nbsp;`os.PathLike`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Directory&nbsp;to&nbsp;save&nbsp;LoRA&nbsp;parameters&nbsp;to.&nbsp;Will&nbsp;be&nbsp;created&nbsp;if&nbsp;it&nbsp;doesn't&nbsp;exist.<br>
&nbsp;&nbsp;&nbsp;&nbsp;unet_lora_layers&nbsp;(`Dict[str,&nbsp;torch.nn.Module]`&nbsp;or&nbsp;`Dict[str,&nbsp;torch.Tensor]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;State&nbsp;dict&nbsp;of&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;`unet`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;text_encoder_lora_layers&nbsp;(`Dict[str,&nbsp;torch.nn.Module]`&nbsp;or&nbsp;`Dict[str,&nbsp;torch.Tensor]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;State&nbsp;dict&nbsp;of&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;`text_encoder`.&nbsp;Must&nbsp;explicitly&nbsp;pass&nbsp;the&nbsp;text<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;encoder&nbsp;LoRA&nbsp;state&nbsp;dict&nbsp;because&nbsp;it&nbsp;comes&nbsp;from&nbsp;ü§ó&nbsp;Transformers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;text_encoder_2_lora_layers&nbsp;(`Dict[str,&nbsp;torch.nn.Module]`&nbsp;or&nbsp;`Dict[str,&nbsp;torch.Tensor]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;State&nbsp;dict&nbsp;of&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;corresponding&nbsp;to&nbsp;the&nbsp;`text_encoder_2`.&nbsp;Must&nbsp;explicitly&nbsp;pass&nbsp;the&nbsp;text<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;encoder&nbsp;LoRA&nbsp;state&nbsp;dict&nbsp;because&nbsp;it&nbsp;comes&nbsp;from&nbsp;ü§ó&nbsp;Transformers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;is_main_process&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;the&nbsp;process&nbsp;calling&nbsp;this&nbsp;is&nbsp;the&nbsp;main&nbsp;process&nbsp;or&nbsp;not.&nbsp;Useful&nbsp;during&nbsp;distributed&nbsp;training&nbsp;and&nbsp;you<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;need&nbsp;to&nbsp;call&nbsp;this&nbsp;function&nbsp;on&nbsp;all&nbsp;processes.&nbsp;In&nbsp;this&nbsp;case,&nbsp;set&nbsp;`is_main_process=True`&nbsp;only&nbsp;on&nbsp;the&nbsp;main<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;process&nbsp;to&nbsp;avoid&nbsp;race&nbsp;conditions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;save_function&nbsp;(`Callable`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;function&nbsp;to&nbsp;use&nbsp;to&nbsp;save&nbsp;the&nbsp;state&nbsp;dictionary.&nbsp;Useful&nbsp;during&nbsp;distributed&nbsp;training&nbsp;when&nbsp;you&nbsp;need&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replace&nbsp;`torch.save`&nbsp;with&nbsp;another&nbsp;method.&nbsp;Can&nbsp;be&nbsp;configured&nbsp;with&nbsp;the&nbsp;environment&nbsp;variable<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`DIFFUSERS_SAVE_MODE`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;safe_serialization&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;save&nbsp;the&nbsp;model&nbsp;using&nbsp;`safetensors`&nbsp;or&nbsp;the&nbsp;traditional&nbsp;PyTorch&nbsp;way&nbsp;with&nbsp;`pickle`.</tt></dd></dl>

<hr>
Data and other attributes inherited from <a href="diffusers.loaders.lora_pipeline.html#StableDiffusionXLLoraLoaderMixin">diffusers.loaders.lora_pipeline.StableDiffusionXLLoraLoaderMixin</a>:<br>
<dl><dt><strong>text_encoder_name</strong> = 'text_encoder'</dl>

<dl><dt><strong>unet_name</strong> = 'unet'</dl>

<hr>
Methods inherited from <a href="diffusers.loaders.lora_base.html#LoraBaseMixin">diffusers.loaders.lora_base.LoraBaseMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-delete_adapters"><strong>delete_adapters</strong></a>(self, adapter_names: Union[List[str], str])</dt><dd><tt>Args:<br>
Deletes&nbsp;the&nbsp;LoRA&nbsp;layers&nbsp;of&nbsp;`adapter_name`&nbsp;for&nbsp;the&nbsp;unet&nbsp;and&nbsp;text-encoder(s).<br>
&nbsp;&nbsp;&nbsp;&nbsp;adapter_names&nbsp;(`Union[List[str],&nbsp;str]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;names&nbsp;of&nbsp;the&nbsp;adapter&nbsp;to&nbsp;delete.&nbsp;Can&nbsp;be&nbsp;a&nbsp;single&nbsp;string&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;strings</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-disable_lora"><strong>disable_lora</strong></a>(self)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-enable_lora"><strong>enable_lora</strong></a>(self)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-get_active_adapters"><strong>get_active_adapters</strong></a>(self) -&gt; List[str]</dt><dd><tt>Gets&nbsp;the&nbsp;list&nbsp;of&nbsp;the&nbsp;current&nbsp;active&nbsp;adapters.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
```python<br>
from&nbsp;diffusers&nbsp;import&nbsp;DiffusionPipeline<br>
&nbsp;<br>
pipeline&nbsp;=&nbsp;DiffusionPipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-from_pretrained">from_pretrained</a>(<br>
&nbsp;&nbsp;&nbsp;&nbsp;"stabilityai/stable-diffusion-xl-base-1.0",<br>
).<a href="#MaskedStableDiffusionXLImg2ImgPipeline-to">to</a>("cuda")<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-load_lora_weights">load_lora_weights</a>("CiroN2022/toy-face",&nbsp;weight_name="toy_face_sdxl.safetensors",&nbsp;adapter_name="toy")<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-get_active_adapters">get_active_adapters</a>()<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-get_list_adapters"><strong>get_list_adapters</strong></a>(self) -&gt; Dict[str, List[str]]</dt><dd><tt>Gets&nbsp;the&nbsp;current&nbsp;list&nbsp;of&nbsp;all&nbsp;available&nbsp;adapters&nbsp;in&nbsp;the&nbsp;pipeline.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-set_adapters"><strong>set_adapters</strong></a>(self, adapter_names: Union[List[str], str], adapter_weights: Union[float, Dict, List[float], List[Dict], NoneType] = None)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-set_lora_device"><strong>set_lora_device</strong></a>(self, adapter_names: List[str], device: Union[torch.device, str, int]) -&gt; None</dt><dd><tt>Moves&nbsp;the&nbsp;LoRAs&nbsp;listed&nbsp;in&nbsp;`adapter_names`&nbsp;to&nbsp;a&nbsp;target&nbsp;device.&nbsp;Useful&nbsp;for&nbsp;offloading&nbsp;the&nbsp;LoRA&nbsp;to&nbsp;the&nbsp;CPU&nbsp;in&nbsp;case<br>
you&nbsp;want&nbsp;to&nbsp;load&nbsp;multiple&nbsp;adapters&nbsp;and&nbsp;free&nbsp;some&nbsp;GPU&nbsp;memory.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;adapter_names&nbsp;(`List[str]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;List&nbsp;of&nbsp;adapters&nbsp;to&nbsp;send&nbsp;device&nbsp;to.<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(`Union[torch.device,&nbsp;str,&nbsp;int]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Device&nbsp;to&nbsp;send&nbsp;the&nbsp;adapters&nbsp;to.&nbsp;Can&nbsp;be&nbsp;either&nbsp;a&nbsp;torch&nbsp;device,&nbsp;a&nbsp;str&nbsp;or&nbsp;an&nbsp;integer.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-unload_lora_weights"><strong>unload_lora_weights</strong></a>(self)</dt><dd><tt>Unloads&nbsp;the&nbsp;LoRA&nbsp;parameters.<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```python<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Assuming&nbsp;`pipeline`&nbsp;is&nbsp;already&nbsp;loaded&nbsp;with&nbsp;the&nbsp;LoRA&nbsp;parameters.<br>
&gt;&gt;&gt;&nbsp;pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-unload_lora_weights">unload_lora_weights</a>()<br>
&gt;&gt;&gt;&nbsp;...<br>
```</tt></dd></dl>

<hr>
Static methods inherited from <a href="diffusers.loaders.lora_base.html#LoraBaseMixin">diffusers.loaders.lora_base.LoraBaseMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-pack_weights"><strong>pack_weights</strong></a>(layers, prefix)</dt></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-write_lora_layers"><strong>write_lora_layers</strong></a>(state_dict: Dict[str, torch.Tensor], save_directory: str, is_main_process: bool, weight_name: str, save_function: Callable, safe_serialization: bool)</dt></dl>

<hr>
Readonly properties inherited from <a href="diffusers.loaders.lora_base.html#LoraBaseMixin">diffusers.loaders.lora_base.LoraBaseMixin</a>:<br>
<dl><dt><strong>lora_scale</strong></dt>
</dl>
<hr>
Data and other attributes inherited from <a href="diffusers.loaders.lora_base.html#LoraBaseMixin">diffusers.loaders.lora_base.LoraBaseMixin</a>:<br>
<dl><dt><strong>num_fused_loras</strong> = 0</dl>

<hr>
Methods inherited from <a href="diffusers.loaders.ip_adapter.html#IPAdapterMixin">diffusers.loaders.ip_adapter.IPAdapterMixin</a>:<br>
<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-load_ip_adapter"><strong>load_ip_adapter</strong></a>(self, pretrained_model_name_or_path_or_dict: Union[str, List[str], Dict[str, torch.Tensor]], subfolder: Union[str, List[str]], weight_name: Union[str, List[str]], image_encoder_folder: Optional[str] = 'image_encoder', **kwargs)</dt><dd><tt>Parameters:<br>
&nbsp;&nbsp;&nbsp;&nbsp;pretrained_model_name_or_path_or_dict&nbsp;(`str`&nbsp;or&nbsp;`List[str]`&nbsp;or&nbsp;`os.PathLike`&nbsp;or&nbsp;`List[os.PathLike]`&nbsp;or&nbsp;`dict`&nbsp;or&nbsp;`List[dict]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Can&nbsp;be&nbsp;either:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;string,&nbsp;the&nbsp;*model&nbsp;id*&nbsp;(for&nbsp;example&nbsp;`google/ddpm-celebahq-256`)&nbsp;of&nbsp;a&nbsp;pretrained&nbsp;model&nbsp;hosted&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;path&nbsp;to&nbsp;a&nbsp;*directory*&nbsp;(for&nbsp;example&nbsp;`./my_model_directory`)&nbsp;containing&nbsp;the&nbsp;model&nbsp;weights&nbsp;saved<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;[`ModelMixin.save_pretrained`].<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;A&nbsp;[torch&nbsp;state<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dict](<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict">https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict</a>).<br>
&nbsp;&nbsp;&nbsp;&nbsp;subfolder&nbsp;(`str`&nbsp;or&nbsp;`List[str]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;subfolder&nbsp;location&nbsp;of&nbsp;a&nbsp;model&nbsp;file&nbsp;within&nbsp;a&nbsp;larger&nbsp;model&nbsp;repository&nbsp;on&nbsp;the&nbsp;Hub&nbsp;or&nbsp;locally.&nbsp;If&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list&nbsp;is&nbsp;passed,&nbsp;it&nbsp;should&nbsp;have&nbsp;the&nbsp;same&nbsp;length&nbsp;as&nbsp;`weight_name`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;weight_name&nbsp;(`str`&nbsp;or&nbsp;`List[str]`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;name&nbsp;of&nbsp;the&nbsp;weight&nbsp;file&nbsp;to&nbsp;load.&nbsp;If&nbsp;a&nbsp;list&nbsp;is&nbsp;passed,&nbsp;it&nbsp;should&nbsp;have&nbsp;the&nbsp;same&nbsp;length&nbsp;as<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`weight_name`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;image_encoder_folder&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`image_encoder`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;subfolder&nbsp;location&nbsp;of&nbsp;the&nbsp;image&nbsp;encoder&nbsp;within&nbsp;a&nbsp;larger&nbsp;model&nbsp;repository&nbsp;on&nbsp;the&nbsp;Hub&nbsp;or&nbsp;locally.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pass&nbsp;`None`&nbsp;to&nbsp;not&nbsp;load&nbsp;the&nbsp;image&nbsp;encoder.&nbsp;If&nbsp;the&nbsp;image&nbsp;encoder&nbsp;is&nbsp;located&nbsp;in&nbsp;a&nbsp;folder&nbsp;inside<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`subfolder`,&nbsp;you&nbsp;only&nbsp;need&nbsp;to&nbsp;pass&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;folder&nbsp;that&nbsp;contains&nbsp;image&nbsp;encoder&nbsp;weights,&nbsp;e.g.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`image_encoder_folder="image_encoder"`.&nbsp;If&nbsp;the&nbsp;image&nbsp;encoder&nbsp;is&nbsp;located&nbsp;in&nbsp;a&nbsp;folder&nbsp;other&nbsp;than<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`subfolder`,&nbsp;you&nbsp;should&nbsp;pass&nbsp;the&nbsp;path&nbsp;to&nbsp;the&nbsp;folder&nbsp;that&nbsp;contains&nbsp;image&nbsp;encoder&nbsp;weights,&nbsp;for&nbsp;example,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`image_encoder_folder="different_subfolder/image_encoder"`.<br>
&nbsp;&nbsp;&nbsp;&nbsp;cache_dir&nbsp;(`Union[str,&nbsp;os.PathLike]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path&nbsp;to&nbsp;a&nbsp;directory&nbsp;where&nbsp;a&nbsp;downloaded&nbsp;pretrained&nbsp;model&nbsp;configuration&nbsp;is&nbsp;cached&nbsp;if&nbsp;the&nbsp;standard&nbsp;cache<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is&nbsp;not&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;force_download&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;to&nbsp;force&nbsp;the&nbsp;(re-)download&nbsp;of&nbsp;the&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files,&nbsp;overriding&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cached&nbsp;versions&nbsp;if&nbsp;they&nbsp;exist.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;proxies&nbsp;(`Dict[str,&nbsp;str]`,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;dictionary&nbsp;of&nbsp;proxy&nbsp;servers&nbsp;to&nbsp;use&nbsp;by&nbsp;protocol&nbsp;or&nbsp;endpoint,&nbsp;for&nbsp;example,&nbsp;`{'http':&nbsp;'foo.bar:3128',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<a href="http://hostname">http://hostname</a>':&nbsp;'foo.bar:4012'}`.&nbsp;The&nbsp;proxies&nbsp;are&nbsp;used&nbsp;on&nbsp;each&nbsp;request.<br>
&nbsp;&nbsp;&nbsp;&nbsp;local_files_only&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Whether&nbsp;to&nbsp;only&nbsp;load&nbsp;local&nbsp;model&nbsp;weights&nbsp;and&nbsp;configuration&nbsp;files&nbsp;or&nbsp;not.&nbsp;If&nbsp;set&nbsp;to&nbsp;`True`,&nbsp;the&nbsp;model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;won't&nbsp;be&nbsp;downloaded&nbsp;from&nbsp;the&nbsp;Hub.<br>
&nbsp;&nbsp;&nbsp;&nbsp;token&nbsp;(`str`&nbsp;or&nbsp;*bool*,&nbsp;*optional*):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;token&nbsp;to&nbsp;use&nbsp;as&nbsp;HTTP&nbsp;bearer&nbsp;authorization&nbsp;for&nbsp;remote&nbsp;files.&nbsp;If&nbsp;`True`,&nbsp;the&nbsp;token&nbsp;generated&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`diffusers-cli&nbsp;login`&nbsp;(stored&nbsp;in&nbsp;`~/.huggingface`)&nbsp;is&nbsp;used.<br>
&nbsp;&nbsp;&nbsp;&nbsp;revision&nbsp;(`str`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`"main"`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;specific&nbsp;model&nbsp;version&nbsp;to&nbsp;use.&nbsp;It&nbsp;can&nbsp;be&nbsp;a&nbsp;branch&nbsp;name,&nbsp;a&nbsp;tag&nbsp;name,&nbsp;a&nbsp;commit&nbsp;id,&nbsp;or&nbsp;any&nbsp;identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allowed&nbsp;by&nbsp;Git.<br>
&nbsp;&nbsp;&nbsp;&nbsp;low_cpu_mem_usage&nbsp;(`bool`,&nbsp;*optional*,&nbsp;defaults&nbsp;to&nbsp;`True`&nbsp;if&nbsp;torch&nbsp;version&nbsp;&gt;=&nbsp;1.9.0&nbsp;else&nbsp;`False`):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Speed&nbsp;up&nbsp;model&nbsp;loading&nbsp;only&nbsp;loading&nbsp;the&nbsp;pretrained&nbsp;weights&nbsp;and&nbsp;not&nbsp;initializing&nbsp;the&nbsp;weights.&nbsp;This&nbsp;also<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tries&nbsp;to&nbsp;not&nbsp;use&nbsp;more&nbsp;than&nbsp;1x&nbsp;model&nbsp;size&nbsp;in&nbsp;CPU&nbsp;memory&nbsp;(including&nbsp;peak&nbsp;memory)&nbsp;while&nbsp;loading&nbsp;the&nbsp;model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Only&nbsp;supported&nbsp;for&nbsp;PyTorch&nbsp;&gt;=&nbsp;1.9.0.&nbsp;If&nbsp;you&nbsp;are&nbsp;using&nbsp;an&nbsp;older&nbsp;version&nbsp;of&nbsp;PyTorch,&nbsp;setting&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;argument&nbsp;to&nbsp;`True`&nbsp;will&nbsp;raise&nbsp;an&nbsp;error.</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-set_ip_adapter_scale"><strong>set_ip_adapter_scale</strong></a>(self, scale)</dt><dd><tt>Set&nbsp;IP-Adapter&nbsp;scales&nbsp;per-transformer&nbsp;block.&nbsp;Input&nbsp;`scale`&nbsp;could&nbsp;be&nbsp;a&nbsp;single&nbsp;config&nbsp;or&nbsp;a&nbsp;list&nbsp;of&nbsp;configs&nbsp;for<br>
granular&nbsp;control&nbsp;over&nbsp;each&nbsp;IP-Adapter&nbsp;behavior.&nbsp;A&nbsp;config&nbsp;can&nbsp;be&nbsp;a&nbsp;float&nbsp;or&nbsp;a&nbsp;dictionary.<br>
&nbsp;<br>
Example:<br>
&nbsp;<br>
```py<br>
#&nbsp;To&nbsp;use&nbsp;original&nbsp;IP-Adapter<br>
scale&nbsp;=&nbsp;1.0<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-set_ip_adapter_scale">set_ip_adapter_scale</a>(scale)<br>
&nbsp;<br>
#&nbsp;To&nbsp;use&nbsp;style&nbsp;block&nbsp;only<br>
scale&nbsp;=&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;"up":&nbsp;{"block_0":&nbsp;[0.0,&nbsp;1.0,&nbsp;0.0]},<br>
}<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-set_ip_adapter_scale">set_ip_adapter_scale</a>(scale)<br>
&nbsp;<br>
#&nbsp;To&nbsp;use&nbsp;style+layout&nbsp;blocks<br>
scale&nbsp;=&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;"down":&nbsp;{"block_2":&nbsp;[0.0,&nbsp;1.0]},<br>
&nbsp;&nbsp;&nbsp;&nbsp;"up":&nbsp;{"block_0":&nbsp;[0.0,&nbsp;1.0,&nbsp;0.0]},<br>
}<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-set_ip_adapter_scale">set_ip_adapter_scale</a>(scale)<br>
&nbsp;<br>
#&nbsp;To&nbsp;use&nbsp;style&nbsp;and&nbsp;layout&nbsp;from&nbsp;2&nbsp;reference&nbsp;images<br>
scales&nbsp;=&nbsp;[{"down":&nbsp;{"block_2":&nbsp;[0.0,&nbsp;1.0]}},&nbsp;{"up":&nbsp;{"block_0":&nbsp;[0.0,&nbsp;1.0,&nbsp;0.0]}}]<br>
pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-set_ip_adapter_scale">set_ip_adapter_scale</a>(scales)<br>
```</tt></dd></dl>

<dl><dt><a name="MaskedStableDiffusionXLImg2ImgPipeline-unload_ip_adapter"><strong>unload_ip_adapter</strong></a>(self)</dt><dd><tt>Unloads&nbsp;the&nbsp;IP&nbsp;Adapter&nbsp;weights<br>
&nbsp;<br>
Examples:<br>
&nbsp;<br>
```python<br>
&gt;&gt;&gt;&nbsp;#&nbsp;Assuming&nbsp;`pipeline`&nbsp;is&nbsp;already&nbsp;loaded&nbsp;with&nbsp;the&nbsp;IP&nbsp;Adapter&nbsp;weights.<br>
&gt;&gt;&gt;&nbsp;pipeline.<a href="#MaskedStableDiffusionXLImg2ImgPipeline-unload_ip_adapter">unload_ip_adapter</a>()<br>
&gt;&gt;&gt;&nbsp;...<br>
```</tt></dd></dl>

</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>Any</strong> = typing.Any<br>
<strong>Callable</strong> = typing.Callable<br>
<strong>Dict</strong> = typing.Dict<br>
<strong>List</strong> = typing.List<br>
<strong>Optional</strong> = typing.Optional<br>
<strong>PipelineImageInput</strong> = typing.Union[PIL.Image.Image, numpy.ndarray, tor...g.List[numpy.ndarray], typing.List[torch.Tensor]]<br>
<strong>Tuple</strong> = typing.Tuple<br>
<strong>Union</strong> = typing.Union<br>
<strong>XLA_AVAILABLE</strong> = False<br>
<strong>logger</strong> = &lt;Logger multigen.pipelines.masked_stable_diffusion_xl_img2img (WARNING)&gt;</td></tr></table>
</body></html>